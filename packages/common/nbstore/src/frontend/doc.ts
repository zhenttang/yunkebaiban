import { groupBy } from 'lodash-es';
import { nanoid } from 'nanoid';
import {
  combineLatest,
  filter,
  first,
  lastValueFrom,
  map,
  Observable,
  ReplaySubject,
  share,
  Subject,
  throttleTime,
} from 'rxjs';
import {
  applyUpdate,
  type Doc as YDoc,
  encodeStateAsUpdate,
  Map as YMap,
  mergeUpdates,
  type Transaction as YTransaction,
} from 'yjs';

import type { DocRecord, DocStorage } from '../storage';
import type { DocSync } from '../sync/doc';
import { AsyncPriorityQueue } from '../utils/async-priority-queue';
import { isEmptyUpdate } from '../utils/is-empty-update';
import { takeUntilAbort } from '../utils/take-until-abort';
import { MANUALLY_STOP, throwIfAborted } from '../utils/throw-if-aborted';

const NBSTORE_ORIGIN = 'nbstore-frontend';

type Job =
  | {
      type: 'load';
      docId: string;
    }
  | {
      type: 'save';
      docId: string;
      update: Uint8Array;
    }
  | {
      type: 'apply';
      docId: string;
      update: Uint8Array;
    };

interface DocFrontendOptions {
  mergeUpdates?: (updates: Uint8Array[]) => Promise<Uint8Array> | Uint8Array;
}

export type DocFrontendDocState = {
  /**
   * some data is available in yjs doc instance
   */
  ready: boolean;
  /**
   * data is loaded from local doc storage and applied to yjs doc instance
   */
  loaded: boolean;
  /**
   * some data is being applied to yjs doc instance, or some data is being saved to local doc storage
   */
  updating: boolean;
  /**
   * the doc is syncing with remote peers
   */
  syncing: boolean;
  /**
   * the doc is synced with remote peers
   */
  synced: boolean;
  /**
   * the doc is retrying to sync with remote peers
   */
  syncRetrying: boolean;
  /**
   * the error message when syncing with remote peers
   */
  syncErrorMessage: string | null;
};

export type DocFrontendState = {
  /**
   * total number of docs
   */
  total: number;
  /**
   * number of docs that have been loaded to yjs doc instance
   */
  loaded: number;
  /**
   * some data is being applied to yjs doc instance, or some data is being saved to local doc storage
   */
  updating: boolean;
  /**
   * number of docs that are syncing with remote peers
   */
  syncing: number;
  /**
   * whether all docs are synced with remote peers
   */
  synced: boolean;
  /**
   * whether the doc is retrying to sync with remote peers
   */
  syncRetrying: boolean;
  /**
   * the error message when syncing with remote peers
   */
  syncErrorMessage: string | null;
};

export class DocFrontend {
  private readonly uniqueId = `frontend:${nanoid()}`;

  private readonly prioritySettings = new Map<string, number>();

  private readonly status = {
    docs: new Map<string, YDoc>(),
    connectedDocs: new Set<string>(),
    readyDocs: new Set<string>(),
    jobDocQueue: new AsyncPriorityQueue(),
    jobMap: new Map<string, Job[]>(),
    currentJob: null as { docId: string; jobs: Job[] } | null,
  };

  private readonly statusUpdatedSubject$ = new Subject<string>();

  private readonly abort = new AbortController();

  constructor(
    public readonly storage: DocStorage,
    private readonly sync: DocSync,
    readonly options: DocFrontendOptions = {}
  ) {}

  private _docState$(docId: string): Observable<DocFrontendDocState> {
    const frontendState$ = new Observable<{
      ready: boolean;
      loaded: boolean;
      updating: boolean;
    }>(subscribe => {
      const next = () => {
        const readyStatus = this.status.readyDocs.has(docId);
        const loadedStatus = this.status.connectedDocs.has(docId);
        const updatingStatus = (this.status.jobMap.get(docId)?.length ?? 0) > 0 ||
            this.status.currentJob?.docId === docId;

        subscribe.next({
          ready: readyStatus,
          loaded: loadedStatus,
          updating: updatingStatus,
        });
      };
      next();
      return this.statusUpdatedSubject$.subscribe(updatedId => {
        if (updatedId === docId) next();
      });
    });
    const syncState$ = this.sync.docState$(docId);
    return combineLatest([frontendState$, syncState$]).pipe(
      map(([frontend, sync]) => ({
        ...frontend,
        synced: sync.synced,
        syncing: sync.syncing,
        syncRetrying: sync.retrying,
        syncErrorMessage: sync.errorMessage,
      }))
    );
  }

  docState$(docId: string): Observable<DocFrontendDocState> {
    return this._docState$(docId).pipe(
      throttleTime(1000, undefined, {
        trailing: true,
        leading: true,
      })
    );
  }

  private readonly _state$ = combineLatest([
    new Observable<{ total: number; loaded: number; updating: boolean }>(
      subscriber => {
        const next = () => {
          subscriber.next({
            total: this.status.docs.size,
            loaded: this.status.connectedDocs.size,
            updating:
              this.status.jobMap.size > 0 || this.status.currentJob !== null,
          });
        };
        next();
        return this.statusUpdatedSubject$.subscribe(() => {
          next();
        });
      }
    ),
    this.sync.state$,
  ]).pipe(
    map(([frontend, sync]) => ({
      total: sync.total ?? frontend.total,
      loaded: frontend.loaded,
      updating: frontend.updating,
      syncing: sync.syncing,
      synced: sync.synced,
      syncRetrying: sync.retrying,
      syncErrorMessage: sync.errorMessage,
    })),
    share({
      connector: () => new ReplaySubject(1),
    })
  ) satisfies Observable<DocFrontendState>;

  state$ = this._state$.pipe(
    throttleTime(1000, undefined, {
      leading: true,
      trailing: true,
    })
  );

  start() {
    if (this.abort.signal.aborted) {
      throw new Error('doc frontend can only start once');
    }
    this.mainLoop(this.abort.signal).catch(error => {
      console.error(error);
    });
  }

  stop() {
    this.abort.abort(MANUALLY_STOP);
  }

  private async mainLoop(signal?: AbortSignal) {

    await this.storage.connection.waitForConnected(signal);


    const dispose = this.storage.subscribeDocUpdate((record, origin) => {
      this.event.onStorageUpdate(record, origin);
    });

    try {

      // wait for storage to connect
      await Promise.race([
        this.storage.connection.waitForConnected(signal),
        new Promise((_, reject) => {
          signal?.addEventListener('abort', reason => {
            reject(reason);
          });
        }),
      ]);


      while (true) {
        throwIfAborted(signal);


        const docId = await this.status.jobDocQueue.asyncPop(signal);

        const jobs = this.status.jobMap.get(docId);
        this.status.jobMap.delete(docId);

        if (!jobs) {
          console.warn('âš ï¸ [DocFrontend.mainLoop] ä½œä¸šåˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡:', {
            docId
          });
          this.statusUpdatedSubject$.next(docId);
          continue;
        }

        this.status.currentJob = { docId, jobs };
        this.statusUpdatedSubject$.next(docId);

        const { apply, load, save } = groupBy(jobs, job => job.type) as {
          [key in Job['type']]?: Job[];
        };

        if (load?.length) {
          await this.jobs.load(load[0] as any, signal);
        }

        if (apply?.length) {
          for (const applyJob of apply) {
            await this.jobs.apply(applyJob as any, signal);
          }
        }

        if (save?.length) {
          await this.jobs.save(docId, save as any, signal);
        }


        this.status.currentJob = null;
        this.statusUpdatedSubject$.next(docId);
      }
    } catch (error) {
      console.error('âŒ [DocFrontend.mainLoop] ä¸»å¾ªçŽ¯é”™è¯¯:', {
        error,
        errorMessage: error instanceof Error ? error.message : String(error),
        errorStack: error instanceof Error ? error.stack : undefined
      });
      throw error;
    } finally {
      dispose();
    }
  }

  /**
   * Connect a doc to the frontend, the doc will sync with the doc storage.
   * @param doc - The doc to connect
   */
  connectDoc(doc: YDoc) {
    this._connectDoc(doc);
  }

  readonly jobs = {
    load: async (job: Job & { type: 'load' }, signal?: AbortSignal) => {
      const doc = this.status.docs.get(job.docId);
      if (!doc) {
        return;
      }
      const existingData = encodeStateAsUpdate(doc);

      if (!isEmptyUpdate(existingData)) {
        this.schedule({
          type: 'save',
          docId: doc.guid,
          update: existingData,
        });
      }

      // mark doc as loaded
      doc.emit('sync', [true, doc]);


      const docRecord = await this.storage.getDoc(job.docId);
      throwIfAborted(signal);


      if (docRecord && !isEmptyUpdate(docRecord.bin)) {
        this.applyUpdate(job.docId, docRecord.bin);
        this.status.readyDocs.add(job.docId);
      } else {
        console.warn('âš ï¸ [DocFrontend.load] æ–‡æ¡£æ•°æ®æ— æ•ˆï¼Œæ— æ³•æ ‡è®°ä¸ºready:', {
          docId: job.docId,
          hasDocRecord: !!docRecord,
          binSize: docRecord?.bin?.length || 0,
          reason: !docRecord ? 'no-doc-record' : 'empty-update'
        });
      }

      this.status.connectedDocs.add(job.docId);
      this.statusUpdatedSubject$.next(job.docId);
    },
    save: async (
      docId: string,
      jobs: (Job & { type: 'save' })[],
      signal?: AbortSignal
    ) => {

      if (!this.status.docs.has(docId)) {
        console.warn('âš ï¸ [DocFrontend.save] ä¿å­˜è·³è¿‡ - æ–‡æ¡£ä¸åœ¨ docs é›†åˆä¸­:', {
          docId,
          docsSize: this.status.docs.size,
          docsList: Array.from(this.status.docs)
        });
        return;
      }

      if (this.status.connectedDocs.has(docId)) {
        const updatesList = jobs.map(j => j.update).filter(update => !isEmptyUpdate(update));

        const merged = await this.mergeUpdates(updatesList);


        throwIfAborted(signal);

        try {
          await this.storage.pushDocUpdate(
            {
              docId,
              bin: merged,
            },
            this.uniqueId
          );
        } catch (error) {
          console.error('âŒ [DocFrontend.save] æŽ¨é€åˆ°å­˜å‚¨å¤±è´¥:', {
            docId,
            error,
            errorMessage: error instanceof Error ? error.message : String(error),
            errorStack: error instanceof Error ? error.stack : undefined
          });
          throw error;
        }
      } else {
        console.warn('âš ï¸ [DocFrontend.save] ä¿å­˜è·³è¿‡ - æ–‡æ¡£ä¸åœ¨ connectedDocs ä¸­:', {
          docId,
          docsSize: this.status.docs.size,
          connectedDocsSize: this.status.connectedDocs.size,
          reason: 'loadä½œä¸šå¯èƒ½æœªå®Œæˆæˆ–å¤±è´¥'
        });
      }
    },
    apply: async (job: Job & { type: 'apply' }, signal?: AbortSignal) => {

      throwIfAborted(signal);

      if (!this.status.docs.has(job.docId)) {
        console.warn('âš ï¸ [DocFrontend.jobs.apply] æ–‡æ¡£ä¸åœ¨ docs ä¸­ï¼Œè·³è¿‡:', {
          docId: job.docId
        });
        return;
      }


      if (this.status.connectedDocs.has(job.docId)) {
        this.applyUpdate(job.docId, job.update);
      } else {
        console.warn('âš ï¸ [DocFrontend.jobs.apply] æ–‡æ¡£ä¸åœ¨ connectedDocs ä¸­ï¼Œè·³è¿‡åº”ç”¨');
      }

      if (!isEmptyUpdate(job.update)) {
        this.status.readyDocs.add(job.docId);
        this.statusUpdatedSubject$.next(job.docId);
      }

    },
  };

  event = {
    onStorageUpdate: (update: DocRecord, origin?: string) => {

      if (origin !== this.uniqueId) {
        this.schedule({
          type: 'apply',
          docId: update.docId,
          update: update.bin,
        });
      } else {
      }
    },
  };

  /**
   * Disconnect a doc from the frontend, the doc will stop syncing with the doc storage.
   * It's not recommended to use this method directly, better to use `doc.destroy()`.
   *
   * @param doc - The doc to disconnect
   */
  disconnectDoc(doc: YDoc) {
    this.status.docs.delete(doc.guid);
    this.status.connectedDocs.delete(doc.guid);
    this.status.readyDocs.delete(doc.guid);
    this.status.jobDocQueue.remove(doc.guid);
    this.status.jobMap.delete(doc.guid);
    this.statusUpdatedSubject$.next(doc.guid);
    doc.off('update', this.handleDocUpdate);
  }

  addPriority(id: string, priority: number) {
    const undoSyncPriority = this.sync?.addPriority(id, priority);
    const oldPriority = this.prioritySettings.get(id) ?? 0;

    this.prioritySettings.set(id, priority);
    this.status.jobDocQueue.setPriority(id, oldPriority + priority);

    return () => {
      const currentPriority = this.prioritySettings.get(id) ?? 0;
      this.prioritySettings.set(id, currentPriority - priority);
      this.status.jobDocQueue.setPriority(id, currentPriority - priority);

      undoSyncPriority?.();
    };
  }

  private _connectDoc(doc: YDoc) {
    if (this.status.docs.has(doc.guid)) {
      console.error('âŒ [DocFrontend._connectDoc] æ–‡æ¡£å·²è¿žæŽ¥ï¼ŒæŠ›å‡ºé”™è¯¯');
      throw new Error('æ–‡æ¡£å·²è¿žæŽ¥');
    }

    this.schedule({
      type: 'load',
      docId: doc.guid,
    });

    this.status.docs.set(doc.guid, doc);
    this.statusUpdatedSubject$.next(doc.guid);

    doc.on('update', this.handleDocUpdate);

    doc.on('destroy', () => {
      this.disconnectDoc(doc);
    });

  }

  private schedule(job: Job) {
    const priority = this.prioritySettings.get(job.docId) ?? 0;
    this.status.jobDocQueue.push(job.docId, priority);

    const existingJobs = this.status.jobMap.get(job.docId) ?? [];
    existingJobs.push(job);
    this.status.jobMap.set(job.docId, existingJobs);

    this.statusUpdatedSubject$.next(job.docId);
  }

  private isApplyingUpdate = false;

  applyUpdate(docId: string, update: Uint8Array) {
    const doc = this.status.docs.get(docId);
    if (doc && !isEmptyUpdate(update)) {
      // æ•°æ®éªŒè¯å’Œè¯¦ç»†æ—¥å¿—
      const firstBytes = Array.from(update.slice(0, 10))
        .map(b => b.toString(16).padStart(2, '0'))
        .join(' ');
      
      const isEmpty = update.byteLength === 0 || 
        (update.byteLength === 2 && update[0] === 0 && update[1] === 0);
      
      // Y.js æ›´æ–°æ•°æ®é€šå¸¸ä»¥ 0x00 æˆ– 0x01 å¼€å§‹
      const looksLikeYjsUpdate = update[0] === 0x00 || update[0] === 0x01;
      
      console.log('[isEmptyUpdate] Y.jsäºŒè¿›åˆ¶æ•°æ®æ£€æŸ¥:', {
        byteLength: update.byteLength,
        isEmpty,
        firstBytes,
        isEmptyPattern: isEmpty,
        looksLikeYjsUpdate
      });
      
      // å¦‚æžœæ•°æ®çœ‹èµ·æ¥ä¸åƒ Y.js æ›´æ–°ï¼Œè®°å½•è­¦å‘Š
      if (!looksLikeYjsUpdate) {
        console.warn('âš ï¸ [applyUpdate] æ•°æ®æ ¼å¼å¯èƒ½ä¸æ­£ç¡®ï¼Œä¸æ˜¯æ ‡å‡†çš„ Y.js æ›´æ–°æ ¼å¼', {
          docId,
          firstByte: update[0],
          expectedFirstByte: '0x00 æˆ– 0x01',
          dataPreview: firstBytes
        });
      }
      
      try {
        this.isApplyingUpdate = true;
        applyUpdate(doc, update, NBSTORE_ORIGIN);
      } catch (err: any) {
        console.error('failed to apply update yjs doc', err);
        console.error('âŒ [applyUpdate] è¯¦ç»†é”™è¯¯ä¿¡æ¯:', {
          docId,
          errorMessage: err?.message || String(err),
          errorName: err?.name || 'Unknown',
          updateSize: update.byteLength,
          firstBytes,
          updatePreview: Array.from(update.slice(0, 50))
        });
        
        // å¦‚æžœæ˜¯ "Integer out of Range" é”™è¯¯ï¼Œæä¾›æ›´å¤šå¸®åŠ©ä¿¡æ¯
        const errorMessage = err?.message || String(err);
        if (errorMessage.includes('Integer out of Range')) {
          console.error('ðŸ’¡ å¯èƒ½çš„åŽŸå› :');
          console.error('  1. åŽç«¯è¿”å›žçš„æ•°æ®ä¸æ˜¯æœ‰æ•ˆçš„ Y.js äºŒè¿›åˆ¶æ ¼å¼');
          console.error('  2. æ•°æ®åœ¨ä¼ è¾“è¿‡ç¨‹ä¸­è¢«æŸå');
          console.error('  3. å‰åŽç«¯ Y.js ç‰ˆæœ¬ä¸ä¸€è‡´');
          console.error('  4. æ•°æ®åº“ä¸­å­˜å‚¨çš„æ•°æ®æ ¼å¼é”™è¯¯');
          console.error('å»ºè®®: æ£€æŸ¥åŽç«¯è¿”å›žçš„æ•°æ®æ ¼å¼ï¼Œç¡®ä¿æ˜¯ Y.js encodeStateAsUpdate ç”Ÿæˆçš„äºŒè¿›åˆ¶æ•°æ®');
        }
      } finally {
        this.isApplyingUpdate = false;
      }
    }
  }

  private readonly handleDocUpdate = (
    update: Uint8Array,
    origin: any,
    doc: YDoc,
    _transaction: YTransaction
  ) => {
    if (origin === NBSTORE_ORIGIN) {
      return;
    }

    if (this.isApplyingUpdate && BUILD_CONFIG.debug) {
      // èŽ·å–å˜æ›´çš„è·¯å¾„åˆ—è¡¨ï¼ˆç”¨äºŽè°ƒè¯•ï¼‰
      const changedKeys = Array.from(doc.share.keys());
      const changedList = changedKeys.join(', ') || '(empty)';
      
      console.warn(`âš ï¸ When nbstore applies a remote update, some code triggers a local change to the doc.
This will causes the document's 'edited by' to become the current user, even if the user has not actually modified the document.
This is usually caused by a coding error and needs to be fixed by the developer.
Changed:
${changedList}
`);
    }

    if (!this.status.docs.has(doc.guid)) {
      console.warn('âš ï¸ [DocFrontend.handleDocUpdate] æ–‡æ¡£ä¸åœ¨ docs ä¸­ï¼Œè·³è¿‡:', {
        docId: doc.guid,
        docsSize: this.status.docs.size
      });
      return;
    }

    this.schedule({
      type: 'save',
      docId: doc.guid,
      update,
    });
  };

  protected mergeUpdates(updates: Uint8Array[]) {
    const merge = this.options?.mergeUpdates ?? mergeUpdates;
    return merge(updates.filter(bin => !isEmptyUpdate(bin)));
  }

  async waitForUpdated(docId?: string, abort?: AbortSignal) {
    const source$: Observable<DocFrontendDocState | DocFrontendState> = docId
      ? this._docState$(docId)
      : this._state$;
    await lastValueFrom(
      source$.pipe(
        filter(status => !status.updating),
        takeUntilAbort(abort),
        first()
      )
    );
    return;
  }

  async waitForDocLoaded(docId: string, abort?: AbortSignal) {
    await lastValueFrom(
      this._docState$(docId).pipe(
        filter(state => state.loaded),
        takeUntilAbort(abort),
        first()
      )
    );
  }

  async waitForSynced(docId?: string, abort?: AbortSignal) {
    await this.waitForUpdated(docId, abort);
    await this.sync.waitForSynced(docId, abort);
  }

  async waitForDocReady(docId: string, abort?: AbortSignal) {
    await lastValueFrom(
      this._docState$(docId).pipe(
        filter(state => state.ready),
        takeUntilAbort(abort),
        first()
      )
    );
  }

  async resetSync() {
    await this.sync.resetSync();
  }
}
