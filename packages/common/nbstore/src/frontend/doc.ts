import { groupBy } from 'lodash-es';
import { nanoid } from 'nanoid';
import {
  combineLatest,
  filter,
  first,
  lastValueFrom,
  map,
  Observable,
  ReplaySubject,
  share,
  Subject,
  throttleTime,
} from 'rxjs';
import {
  applyUpdate,
  type Doc as YDoc,
  encodeStateAsUpdate,
  Map as YMap,
  mergeUpdates,
  type Transaction as YTransaction,
} from 'yjs';

import type { DocRecord, DocStorage } from '../storage';
import type { DocSync } from '../sync/doc';
import { AsyncPriorityQueue } from '../utils/async-priority-queue';
import { isEmptyUpdate } from '../utils/is-empty-update';
import { takeUntilAbort } from '../utils/take-until-abort';
import { MANUALLY_STOP, throwIfAborted } from '../utils/throw-if-aborted';

const NBSTORE_ORIGIN = 'nbstore-frontend';

type Job =
  | {
      type: 'load';
      docId: string;
    }
  | {
      type: 'save';
      docId: string;
      update: Uint8Array;
    }
  | {
      type: 'apply';
      docId: string;
      update: Uint8Array;
    };

interface DocFrontendOptions {
  mergeUpdates?: (updates: Uint8Array[]) => Promise<Uint8Array> | Uint8Array;
}

export type DocFrontendDocState = {
  /**
   * some data is available in yjs doc instance
   */
  ready: boolean;
  /**
   * data is loaded from local doc storage and applied to yjs doc instance
   */
  loaded: boolean;
  /**
   * some data is being applied to yjs doc instance, or some data is being saved to local doc storage
   */
  updating: boolean;
  /**
   * the doc is syncing with remote peers
   */
  syncing: boolean;
  /**
   * the doc is synced with remote peers
   */
  synced: boolean;
  /**
   * the doc is retrying to sync with remote peers
   */
  syncRetrying: boolean;
  /**
   * the error message when syncing with remote peers
   */
  syncErrorMessage: string | null;
};

export type DocFrontendState = {
  /**
   * total number of docs
   */
  total: number;
  /**
   * number of docs that have been loaded to yjs doc instance
   */
  loaded: number;
  /**
   * some data is being applied to yjs doc instance, or some data is being saved to local doc storage
   */
  updating: boolean;
  /**
   * number of docs that are syncing with remote peers
   */
  syncing: number;
  /**
   * whether all docs are synced with remote peers
   */
  synced: boolean;
  /**
   * whether the doc is retrying to sync with remote peers
   */
  syncRetrying: boolean;
  /**
   * the error message when syncing with remote peers
   */
  syncErrorMessage: string | null;
};

export class DocFrontend {
  private readonly uniqueId = `frontend:${nanoid()}`;

  private readonly prioritySettings = new Map<string, number>();

  private readonly status = {
    docs: new Map<string, YDoc>(),
    connectedDocs: new Set<string>(),
    readyDocs: new Set<string>(),
    jobDocQueue: new AsyncPriorityQueue(),
    jobMap: new Map<string, Job[]>(),
    currentJob: null as { docId: string; jobs: Job[] } | null,
  };

  private readonly statusUpdatedSubject$ = new Subject<string>();

  private readonly abort = new AbortController();

  constructor(
    public readonly storage: DocStorage,
    private readonly sync: DocSync,
    readonly options: DocFrontendOptions = {}
  ) {}

  private _docState$(docId: string): Observable<DocFrontendDocState> {
    const frontendState$ = new Observable<{
      ready: boolean;
      loaded: boolean;
      updating: boolean;
    }>(subscribe => {
      const next = () => {
        const readyStatus = this.status.readyDocs.has(docId);
        const loadedStatus = this.status.connectedDocs.has(docId);
        const updatingStatus = (this.status.jobMap.get(docId)?.length ?? 0) > 0 ||
            this.status.currentJob?.docId === docId;
            
        console.log('ðŸ“Š [DocFrontend] æ–‡æ¡£çŠ¶æ€æ›´æ–°:', {
          docId: docId,
          ready: readyStatus,
          loaded: loadedStatus,
          updating: updatingStatus,
          readyDocsCount: this.status.readyDocs.size,
          connectedDocsCount: this.status.connectedDocs.size,
          timestamp: new Date().toISOString()
        });
        
        subscribe.next({
          ready: readyStatus,
          loaded: loadedStatus,
          updating: updatingStatus,
        });
      };
      next();
      return this.statusUpdatedSubject$.subscribe(updatedId => {
        if (updatedId === docId) next();
      });
    });
    const syncState$ = this.sync.docState$(docId);
    return combineLatest([frontendState$, syncState$]).pipe(
      map(([frontend, sync]) => ({
        ...frontend,
        synced: sync.synced,
        syncing: sync.syncing,
        syncRetrying: sync.retrying,
        syncErrorMessage: sync.errorMessage,
      }))
    );
  }

  docState$(docId: string): Observable<DocFrontendDocState> {
    return this._docState$(docId).pipe(
      throttleTime(1000, undefined, {
        trailing: true,
        leading: true,
      })
    );
  }

  private readonly _state$ = combineLatest([
    new Observable<{ total: number; loaded: number; updating: boolean }>(
      subscriber => {
        const next = () => {
          subscriber.next({
            total: this.status.docs.size,
            loaded: this.status.connectedDocs.size,
            updating:
              this.status.jobMap.size > 0 || this.status.currentJob !== null,
          });
        };
        next();
        return this.statusUpdatedSubject$.subscribe(() => {
          next();
        });
      }
    ),
    this.sync.state$,
  ]).pipe(
    map(([frontend, sync]) => ({
      total: sync.total ?? frontend.total,
      loaded: frontend.loaded,
      updating: frontend.updating,
      syncing: sync.syncing,
      synced: sync.synced,
      syncRetrying: sync.retrying,
      syncErrorMessage: sync.errorMessage,
    })),
    share({
      connector: () => new ReplaySubject(1),
    })
  ) satisfies Observable<DocFrontendState>;

  state$ = this._state$.pipe(
    throttleTime(1000, undefined, {
      leading: true,
      trailing: true,
    })
  );

  start() {
    if (this.abort.signal.aborted) {
      throw new Error('doc frontend can only start once');
    }
    this.mainLoop(this.abort.signal).catch(error => {
      console.error(error);
    });
  }

  stop() {
    this.abort.abort(MANUALLY_STOP);
  }

  private async mainLoop(signal?: AbortSignal) {
    console.log('ðŸš€ [DocFrontend.mainLoop] ä¸»å¾ªçŽ¯å¯åŠ¨:', {
      timestamp: new Date().toISOString()
    });

    await this.storage.connection.waitForConnected(signal);

    console.log('âœ… [DocFrontend.mainLoop] Storage è¿žæŽ¥æˆåŠŸï¼Œè®¢é˜…æ›´æ–°äº‹ä»¶');

    const dispose = this.storage.subscribeDocUpdate((record, origin) => {
      console.log('ðŸ“¨ [DocFrontend.mainLoop] æ”¶åˆ° storage æ›´æ–°äº‹ä»¶:', {
        docId: record.docId,
        binSize: record.bin?.length,
        origin: origin,
        timestamp: new Date().toISOString()
      });
      this.event.onStorageUpdate(record, origin);
    });

    try {
      console.log('â³ [DocFrontend.mainLoop] ç­‰å¾… storage è¿žæŽ¥...');

      // wait for storage to connect
      await Promise.race([
        this.storage.connection.waitForConnected(signal),
        new Promise((_, reject) => {
          signal?.addEventListener('abort', reason => {
            reject(reason);
          });
        }),
      ]);

      console.log('âœ… [DocFrontend.mainLoop] Storage è¿žæŽ¥å°±ç»ªï¼Œå¼€å§‹å¤„ç†ä½œä¸šé˜Ÿåˆ—');

      while (true) {
        throwIfAborted(signal);

        console.log('â³ [DocFrontend.mainLoop] ç­‰å¾…ä¸‹ä¸€ä¸ªä½œä¸š...');

        const docId = await this.status.jobDocQueue.asyncPop(signal);

        console.log('ðŸ“‹ [DocFrontend.mainLoop] ä»Žé˜Ÿåˆ—å–å‡ºä½œä¸š:', {
          docId,
          timestamp: new Date().toISOString()
        });

        const jobs = this.status.jobMap.get(docId);
        this.status.jobMap.delete(docId);

        if (!jobs) {
          console.warn('âš ï¸ [DocFrontend.mainLoop] ä½œä¸šåˆ—è¡¨ä¸ºç©ºï¼Œè·³è¿‡:', {
            docId
          });
          this.statusUpdatedSubject$.next(docId);
          continue;
        }

        console.log('ðŸ”„ [DocFrontend.mainLoop] å¼€å§‹å¤„ç†ä½œä¸š:', {
          docId,
          jobsCount: jobs.length,
          jobTypes: jobs.map(j => j.type).join(', ')
        });

        this.status.currentJob = { docId, jobs };
        this.statusUpdatedSubject$.next(docId);

        const { apply, load, save } = groupBy(jobs, job => job.type) as {
          [key in Job['type']]?: Job[];
        };

        if (load?.length) {
          console.log('ðŸ“¥ [DocFrontend.mainLoop] æ‰§è¡Œ load ä½œä¸š:', {
            docId,
            loadJobsCount: load.length
          });
          await this.jobs.load(load[0] as any, signal);
        }

        if (apply?.length) {
          console.log('ðŸ”„ [DocFrontend.mainLoop] æ‰§è¡Œ apply ä½œä¸š:', {
            docId,
            applyJobsCount: apply.length
          });
        }

        for (const applyJob of apply ?? []) {
          await this.jobs.apply(applyJob as any, signal);
        }

        if (save?.length) {
          console.log('ðŸ’¾ [DocFrontend.mainLoop] æ‰§è¡Œ save ä½œä¸š:', {
            docId,
            saveJobsCount: save.length
          });
          await this.jobs.save(docId, save as any, signal);
        }

        console.log('âœ… [DocFrontend.mainLoop] ä½œä¸šå¤„ç†å®Œæˆ:', {
          docId
        });

        this.status.currentJob = null;
        this.statusUpdatedSubject$.next(docId);
      }
    } catch (error) {
      console.error('âŒ [DocFrontend.mainLoop] ä¸»å¾ªçŽ¯é”™è¯¯:', {
        error,
        errorMessage: error instanceof Error ? error.message : String(error),
        errorStack: error instanceof Error ? error.stack : undefined
      });
      throw error;
    } finally {
      console.log('ðŸ›‘ [DocFrontend.mainLoop] ä¸»å¾ªçŽ¯ç»“æŸï¼Œæ¸…ç†è®¢é˜…');
      dispose();
    }
  }

  /**
   * Connect a doc to the frontend, the doc will sync with the doc storage.
   * @param doc - The doc to connect
   */
  connectDoc(doc: YDoc) {
    this._connectDoc(doc);
  }

  readonly jobs = {
    load: async (job: Job & { type: 'load' }, signal?: AbortSignal) => {
      const doc = this.status.docs.get(job.docId);
      if (!doc) {
        return;
      }
      const existingData = encodeStateAsUpdate(doc);

      if (!isEmptyUpdate(existingData)) {
        this.schedule({
          type: 'save',
          docId: doc.guid,
          update: existingData,
        });
      }

      // mark doc as loaded
      doc.emit('sync', [true, doc]);

      console.log('ðŸ“ž [DocFrontend] å‡†å¤‡è°ƒç”¨storage.getDoc:', {
        docId: job.docId,
        storageType: this.storage.constructor.name,
        storageIdentifier: (this.storage as any).constructor.identifier || 'unknown',
        hasGetDocMethod: typeof this.storage.getDoc === 'function',
        storageInstance: !!this.storage
      });

      const docRecord = await this.storage.getDoc(job.docId);
      throwIfAborted(signal);

      console.log('ðŸ” [DocFrontend] æ–‡æ¡£åŠ è½½æ£€æŸ¥:', {
        docId: job.docId,
        hasDocRecord: !!docRecord,
        binSize: docRecord?.bin?.length || 0,
        isEmptyUpdate: docRecord ? isEmptyUpdate(docRecord.bin) : 'no-record',
        storageType: this.storage.constructor.name,
        storageIdentifier: (this.storage as any).constructor.identifier || 'unknown',
        timestamp: new Date().toISOString()
      });

      if (docRecord && !isEmptyUpdate(docRecord.bin)) {
        console.log('âœ… [DocFrontend.load] æ–‡æ¡£æ•°æ®æœ‰æ•ˆï¼Œåº”ç”¨æ›´æ–°å¹¶æ ‡è®°ä¸ºready:', {
          docId: job.docId,
          binSize: docRecord.bin.length,
          binHex: Array.from(docRecord.bin.slice(0, 20)).map(b => b.toString(16).padStart(2, '0')).join(' ')
        });
        this.applyUpdate(job.docId, docRecord.bin);
        this.status.readyDocs.add(job.docId);
      } else {
        console.warn('âš ï¸ [DocFrontend.load] æ–‡æ¡£æ•°æ®æ— æ•ˆï¼Œæ— æ³•æ ‡è®°ä¸ºready:', {
          docId: job.docId,
          hasDocRecord: !!docRecord,
          binSize: docRecord?.bin?.length || 0,
          reason: !docRecord ? 'no-doc-record' : 'empty-update'
        });
      }

      console.log('ðŸŽ¯ [DocFrontend.load] å…³é”®ï¼šå°†æ–‡æ¡£æ·»åŠ åˆ° connectedDocs:', {
        docId: job.docId,
        beforeSize: this.status.connectedDocs.size,
        beforeList: Array.from(this.status.connectedDocs)
      });

      this.status.connectedDocs.add(job.docId);

      console.log('âœ… [DocFrontend.load] load ä½œä¸šå®Œæˆï¼ŒconnectedDocs å·²æ›´æ–°:', {
        docId: job.docId,
        afterSize: this.status.connectedDocs.size,
        afterList: Array.from(this.status.connectedDocs),
        isNowInConnectedDocs: this.status.connectedDocs.has(job.docId)
      });

      this.statusUpdatedSubject$.next(job.docId);
    },
    save: async (
      docId: string,
      jobs: (Job & { type: 'save' })[],
      signal?: AbortSignal
    ) => {
      console.log('ðŸ’¾ [DocFrontend.save] ä¿å­˜ä½œä¸šå¼€å§‹:', {
        docId,
        jobsCount: jobs.length,
        totalUpdatesSize: jobs.reduce((sum, j) => sum + j.update.length, 0),
        timestamp: new Date().toISOString()
      });

      if (!this.status.docs.has(docId)) {
        console.warn('âš ï¸ [DocFrontend.save] ä¿å­˜è·³è¿‡ - æ–‡æ¡£ä¸åœ¨ docs é›†åˆä¸­:', {
          docId,
          docsSize: this.status.docs.size,
          docsList: Array.from(this.status.docs)
        });
        return;
      }

      console.log('âœ… [DocFrontend.save] æ–‡æ¡£åœ¨ docs é›†åˆä¸­ï¼Œæ£€æŸ¥ connectedDocs:', {
        docId,
        isInConnectedDocs: this.status.connectedDocs.has(docId),
        connectedDocsSize: this.status.connectedDocs.size,
        connectedDocsList: Array.from(this.status.connectedDocs)
      });

      if (this.status.connectedDocs.has(docId)) {
        const updatesList = jobs.map(j => j.update).filter(update => !isEmptyUpdate(update));
        console.log('ðŸ”„ [DocFrontend.save] åˆå¹¶æ›´æ–°ä¸­:', {
          docId,
          updatesCount: updatesList.length,
          totalSize: updatesList.reduce((sum, u) => sum + u.length, 0)
        });

        const merged = await this.mergeUpdates(updatesList);

        console.log('ðŸ”„ [DocFrontend.save] åˆå¹¶å®Œæˆï¼Œå‡†å¤‡æŽ¨é€åˆ°å­˜å‚¨:', {
          docId,
          mergedSize: merged.length,
          isEmpty: isEmptyUpdate(merged),
          storageType: this.storage?.constructor?.name || 'unknown'
        });

        throwIfAborted(signal);

        try {
          await this.storage.pushDocUpdate(
            {
              docId,
              bin: merged,
            },
            this.uniqueId
          );
          console.log('âœ… [DocFrontend.save] æŽ¨é€åˆ°å­˜å‚¨æˆåŠŸ:', {
            docId,
            dataSize: merged.length
          });
        } catch (error) {
          console.error('âŒ [DocFrontend.save] æŽ¨é€åˆ°å­˜å‚¨å¤±è´¥:', {
            docId,
            error,
            errorMessage: error instanceof Error ? error.message : String(error),
            errorStack: error instanceof Error ? error.stack : undefined
          });
          throw error;
        }
      } else {
        console.warn('âš ï¸ [DocFrontend.save] ä¿å­˜è·³è¿‡ - æ–‡æ¡£ä¸åœ¨ connectedDocs ä¸­:', {
          docId,
          docsSize: this.status.docs.size,
          connectedDocsSize: this.status.connectedDocs.size,
          reason: 'loadä½œä¸šå¯èƒ½æœªå®Œæˆæˆ–å¤±è´¥'
        });
      }
    },
    apply: async (job: Job & { type: 'apply' }, signal?: AbortSignal) => {
      console.log('ðŸ”„ [DocFrontend.jobs.apply] Apply ä½œä¸šå¼€å§‹:', {
        docId: job.docId,
        updateSize: job.update.length,
        timestamp: new Date().toISOString()
      });

      throwIfAborted(signal);

      if (!this.status.docs.has(job.docId)) {
        console.warn('âš ï¸ [DocFrontend.jobs.apply] æ–‡æ¡£ä¸åœ¨ docs ä¸­ï¼Œè·³è¿‡:', {
          docId: job.docId
        });
        return;
      }

      console.log('ðŸ” [DocFrontend.jobs.apply] æ£€æŸ¥ connectedDocs:', {
        docId: job.docId,
        isInConnectedDocs: this.status.connectedDocs.has(job.docId)
      });

      if (this.status.connectedDocs.has(job.docId)) {
        console.log('âœ… [DocFrontend.jobs.apply] åº”ç”¨æ›´æ–°åˆ° YJS æ–‡æ¡£');
        this.applyUpdate(job.docId, job.update);
      } else {
        console.warn('âš ï¸ [DocFrontend.jobs.apply] æ–‡æ¡£ä¸åœ¨ connectedDocs ä¸­ï¼Œè·³è¿‡åº”ç”¨');
      }

      if (!isEmptyUpdate(job.update)) {
        console.log('âœ… [DocFrontend.jobs.apply] æ ‡è®°æ–‡æ¡£ä¸º ready');
        this.status.readyDocs.add(job.docId);
        this.statusUpdatedSubject$.next(job.docId);
      }

      console.log('âœ… [DocFrontend.jobs.apply] Apply ä½œä¸šå®Œæˆ');
    },
  };

  event = {
    onStorageUpdate: (update: DocRecord, origin?: string) => {
      console.log('ðŸ“¨ [DocFrontend.event.onStorageUpdate] æ”¶åˆ°å­˜å‚¨æ›´æ–°äº‹ä»¶:', {
        docId: update.docId,
        binSize: update.bin?.length,
        origin: origin,
        uniqueId: this.uniqueId,
        timestamp: new Date().toISOString()
      });

      if (origin !== this.uniqueId) {
        console.log('âœ… [DocFrontend.event.onStorageUpdate] åˆ›å»º apply ä½œä¸š');
        this.schedule({
          type: 'apply',
          docId: update.docId,
          update: update.bin,
        });
      } else {
        console.log('âš ï¸ [DocFrontend.event.onStorageUpdate] æ›´æ–°æ¥è‡ªè‡ªå·±ï¼Œè·³è¿‡');
      }
    },
  };

  /**
   * Disconnect a doc from the frontend, the doc will stop syncing with the doc storage.
   * It's not recommended to use this method directly, better to use `doc.destroy()`.
   *
   * @param doc - The doc to disconnect
   */
  disconnectDoc(doc: YDoc) {
    this.status.docs.delete(doc.guid);
    this.status.connectedDocs.delete(doc.guid);
    this.status.readyDocs.delete(doc.guid);
    this.status.jobDocQueue.remove(doc.guid);
    this.status.jobMap.delete(doc.guid);
    this.statusUpdatedSubject$.next(doc.guid);
    doc.off('update', this.handleDocUpdate);
  }

  addPriority(id: string, priority: number) {
    const undoSyncPriority = this.sync?.addPriority(id, priority);
    const oldPriority = this.prioritySettings.get(id) ?? 0;

    this.prioritySettings.set(id, priority);
    this.status.jobDocQueue.setPriority(id, oldPriority + priority);

    return () => {
      const currentPriority = this.prioritySettings.get(id) ?? 0;
      this.prioritySettings.set(id, currentPriority - priority);
      this.status.jobDocQueue.setPriority(id, currentPriority - priority);

      undoSyncPriority?.();
    };
  }

  private _connectDoc(doc: YDoc) {
    console.log('ðŸ”— [DocFrontend._connectDoc] è¿žæŽ¥æ–‡æ¡£:', {
      docId: doc.guid,
      alreadyConnected: this.status.docs.has(doc.guid),
      timestamp: new Date().toISOString()
    });

    if (this.status.docs.has(doc.guid)) {
      console.error('âŒ [DocFrontend._connectDoc] æ–‡æ¡£å·²è¿žæŽ¥ï¼ŒæŠ›å‡ºé”™è¯¯');
      throw new Error('æ–‡æ¡£å·²è¿žæŽ¥');
    }

    console.log('ðŸ“‹ [DocFrontend._connectDoc] åˆ›å»º load ä½œä¸š');
    this.schedule({
      type: 'load',
      docId: doc.guid,
    });

    console.log('âœ… [DocFrontend._connectDoc] å°†æ–‡æ¡£æ·»åŠ åˆ° docs é›†åˆ');
    this.status.docs.set(doc.guid, doc);
    this.statusUpdatedSubject$.next(doc.guid);

    console.log('ðŸ‘‚ [DocFrontend._connectDoc] æ³¨å†Œ update äº‹ä»¶ç›‘å¬å™¨');
    doc.on('update', this.handleDocUpdate);

    console.log('ðŸ‘‚ [DocFrontend._connectDoc] æ³¨å†Œ destroy äº‹ä»¶ç›‘å¬å™¨');
    doc.on('destroy', () => {
      console.log('ðŸ—‘ï¸ [DocFrontend._connectDoc] æ–‡æ¡£è¢«é”€æ¯ï¼Œæ–­å¼€è¿žæŽ¥:', {
        docId: doc.guid
      });
      this.disconnectDoc(doc);
    });

    console.log('âœ… [DocFrontend._connectDoc] æ–‡æ¡£è¿žæŽ¥å®Œæˆ');
  }

  private schedule(job: Job) {
    console.log('ðŸ“‹ [DocFrontend.schedule] è°ƒåº¦ä½œä¸š:', {
      jobType: job.type,
      docId: job.docId,
      updateSize: job.type === 'save' || job.type === 'apply' ? job.update.length : undefined,
      timestamp: new Date().toISOString()
    });

    const priority = this.prioritySettings.get(job.docId) ?? 0;
    this.status.jobDocQueue.push(job.docId, priority);

    const existingJobs = this.status.jobMap.get(job.docId) ?? [];
    existingJobs.push(job);
    this.status.jobMap.set(job.docId, existingJobs);

    console.log('ðŸ“‹ [DocFrontend.schedule] ä½œä¸šå·²åŠ å…¥é˜Ÿåˆ—:', {
      jobType: job.type,
      docId: job.docId,
      queuedJobsCount: existingJobs.length,
      priority: priority
    });

    this.statusUpdatedSubject$.next(job.docId);
  }

  private isApplyingUpdate = false;

  applyUpdate(docId: string, update: Uint8Array) {
    const doc = this.status.docs.get(docId);
    if (doc && !isEmptyUpdate(update)) {
      try {
        this.isApplyingUpdate = true;
        applyUpdate(doc, update, NBSTORE_ORIGIN);
      } catch (err) {
        console.error('failed to apply update yjs doc', err);
      } finally {
        this.isApplyingUpdate = false;
      }
    }
  }

  private readonly handleDocUpdate = (
    update: Uint8Array,
    origin: any,
    doc: YDoc,
    transaction: YTransaction
  ) => {
    console.log('ðŸ“ [DocFrontend.handleDocUpdate] YJS æ–‡æ¡£æ›´æ–°äº‹ä»¶:', {
      docId: doc.guid,
      updateSize: update.length,
      origin: origin,
      isNBStoreOrigin: origin === NBSTORE_ORIGIN,
      isApplyingUpdate: this.isApplyingUpdate,
      timestamp: new Date().toISOString()
    });

    if (origin === NBSTORE_ORIGIN) {
      console.log('âš ï¸ [DocFrontend.handleDocUpdate] æ¥è‡ª NBStore çš„æ›´æ–°ï¼Œè·³è¿‡:', {
        docId: doc.guid
      });
      return;
    }

    if (this.isApplyingUpdate && BUILD_CONFIG.debug) {
      let changedList = '';
      for (const [changed, keys] of transaction.changed) {
        for (const key of keys) {
          if (changed instanceof YMap && key) {
            changedList += `${key} => ${changed.get(key)}\n`;
          }
        }
      }
      console.warn(`âš ï¸ When nbstore applies a remote update, some code triggers a local change to the doc.
This will causes the document's 'edited by' to become the current user, even if the user has not actually modified the document.
This is usually caused by a coding error and needs to be fixed by the developer.
Changed:
${changedList}
`);
    }

    if (!this.status.docs.has(doc.guid)) {
      console.warn('âš ï¸ [DocFrontend.handleDocUpdate] æ–‡æ¡£ä¸åœ¨ docs ä¸­ï¼Œè·³è¿‡:', {
        docId: doc.guid,
        docsSize: this.status.docs.size
      });
      return;
    }

    console.log('âœ… [DocFrontend.handleDocUpdate] åˆ›å»º save ä½œä¸š:', {
      docId: doc.guid,
      updateSize: update.length
    });

    this.schedule({
      type: 'save',
      docId: doc.guid,
      update,
    });
  };

  protected mergeUpdates(updates: Uint8Array[]) {
    const merge = this.options?.mergeUpdates ?? mergeUpdates;

    return merge(updates.filter(bin => !isEmptyUpdate(bin)));
  }

  async waitForUpdated(docId?: string, abort?: AbortSignal) {
    const source$: Observable<DocFrontendDocState | DocFrontendState> = docId
      ? this._docState$(docId)
      : this._state$;
    await lastValueFrom(
      source$.pipe(
        filter(status => !status.updating),
        takeUntilAbort(abort),
        first()
      )
    );
    return;
  }

  async waitForDocLoaded(docId: string, abort?: AbortSignal) {
    await lastValueFrom(
      this._docState$(docId).pipe(
        filter(state => state.loaded),
        takeUntilAbort(abort),
        first()
      )
    );
  }

  async waitForSynced(docId?: string, abort?: AbortSignal) {
    await this.waitForUpdated(docId, abort);
    await this.sync.waitForSynced(docId, abort);
  }

  async waitForDocReady(docId: string, abort?: AbortSignal) {
    await lastValueFrom(
      this._docState$(docId).pipe(
        filter(state => state.ready),
        takeUntilAbort(abort),
        first()
      )
    );
  }

  async resetSync() {
    await this.sync.resetSync();
  }
}
