import initSqlJs, { type Database, type SqlJsStatic } from 'sql.js';

import {
  type BlobRecord,
  type DocClock,
  type DocRecord,
  type ListedBlobRecord,
  parseUniversalId,
  type SpaceType,
} from '@yunke/nbstore';
import type { NativeDBApis } from '@yunke/nbstore/sqlite';
import type { NativeDBV1Apis } from '@yunke/nbstore/sqlite/v1';
import { DebugLogger } from '@yunke/debug';
import { mergeUpdates } from 'yjs';

import {
  ensureHandlePermission,
  loadOfflineRootHandle,
} from './offline-file-handle';

const SQLITE_SCHEMA_VERSION = 1;
const OFFLINE_DEBUG =
  typeof BUILD_CONFIG !== 'undefined' && BUILD_CONFIG.debug === true;

// å…¨å±€å­˜å‚¨é”™è¯¯äº‹ä»¶ç±»å‹
export interface StorageErrorEvent {
  type: 'write-failure' | 'data-loss' | 'offline-overflow' | 'storage-low' | 'integrity-error';
  message: string;
  details?: Record<string, unknown>;
}

// å­˜å‚¨ç©ºé—´çŠ¶æ€
export interface StorageQuotaStatus {
  usage: number;        // å·²ç”¨ç©ºé—´ (bytes)
  quota: number;        // æ€»é…é¢ (bytes)
  percentUsed: number;  // ä½¿ç”¨ç™¾åˆ†æ¯”
  isLow: boolean;       // æ˜¯å¦ç©ºé—´ä¸è¶³
}

// å­˜å‚¨ç©ºé—´é¢„è­¦é˜ˆå€¼
const STORAGE_WARNING_THRESHOLD = 0.8;  // 80% è§¦å‘è­¦å‘Š
const STORAGE_CRITICAL_THRESHOLD = 0.95; // 95% è§¦å‘ä¸¥é‡è­¦å‘Š

declare global {
  interface WindowEventMap {
    'yunke-storage-error': CustomEvent<StorageErrorEvent>;
  }
}

// å‘é€å­˜å‚¨é”™è¯¯é€šçŸ¥
const emitStorageError = (error: StorageErrorEvent) => {
  if (typeof window !== 'undefined') {
    window.dispatchEvent(
      new CustomEvent('yunke-storage-error', { detail: error })
    );
  }
};

/**
 * ğŸ”§ P0 ä¼˜åŒ–ï¼šæ£€æŸ¥å­˜å‚¨é…é¢
 * ä½¿ç”¨ Storage API æ£€æŸ¥å¯ç”¨å­˜å‚¨ç©ºé—´
 */
export async function checkStorageQuota(): Promise<StorageQuotaStatus | null> {
  if (typeof navigator === 'undefined' || !navigator.storage?.estimate) {
    return null;
  }

  try {
    const estimate = await navigator.storage.estimate();
    const usage = estimate.usage ?? 0;
    const quota = estimate.quota ?? 0;
    
    if (quota === 0) return null;
    
    const percentUsed = usage / quota;
    const isLow = percentUsed >= STORAGE_WARNING_THRESHOLD;
    
    return { usage, quota, percentUsed, isLow };
  } catch (error) {
    logWarn('æ£€æŸ¥å­˜å‚¨é…é¢å¤±è´¥', {
      error: error instanceof Error ? error.message : String(error),
    });
    return null;
  }
}

/**
 * ğŸ”§ P0 ä¼˜åŒ–ï¼šæ£€æŸ¥å¹¶å‘é€å­˜å‚¨ç©ºé—´é¢„è­¦
 */
export async function checkAndWarnStorageQuota(): Promise<void> {
  const status = await checkStorageQuota();
  if (!status) return;
  
  const usedMB = (status.usage / (1024 * 1024)).toFixed(1);
  const quotaMB = (status.quota / (1024 * 1024)).toFixed(1);
  const percentStr = (status.percentUsed * 100).toFixed(1);
  
  if (status.percentUsed >= STORAGE_CRITICAL_THRESHOLD) {
    logWarn('å­˜å‚¨ç©ºé—´ä¸¥é‡ä¸è¶³', {
      usage: status.usage,
      quota: status.quota,
      percent: status.percentUsed,
    });
    emitStorageError({
      type: 'storage-low',
      message: `å­˜å‚¨ç©ºé—´ä¸¥é‡ä¸è¶³ï¼å·²ä½¿ç”¨ ${usedMB}MB / ${quotaMB}MB (${percentStr}%)ã€‚è¯·æ¸…ç†ç©ºé—´æˆ–å¯¼å‡ºæ•°æ®ã€‚`,
      details: status,
    });
  } else if (status.percentUsed >= STORAGE_WARNING_THRESHOLD) {
    logWarn('å­˜å‚¨ç©ºé—´ä¸è¶³', {
      usage: status.usage,
      quota: status.quota,
      percent: status.percentUsed,
    });
    emitStorageError({
      type: 'storage-low',
      message: `å­˜å‚¨ç©ºé—´ä¸è¶³ï¼Œå·²ä½¿ç”¨ ${usedMB}MB / ${quotaMB}MB (${percentStr}%)ã€‚å»ºè®®æ¸…ç†ä¸éœ€è¦çš„å·¥ä½œåŒºã€‚`,
      details: status,
    });
  }
}

// ç»Ÿä¸€æ—¥å¿—å™¨
const logger = new DebugLogger('yunke:offline-db');

const logInfo = (message: string, data?: Record<string, unknown>) => {
  if (!OFFLINE_DEBUG) return;
  if (data) {
    logger.info(message, data);
  } else {
    logger.info(message);
  }
};

const logWarn = (message: string, data?: Record<string, unknown>) => {
  if (!OFFLINE_DEBUG) return;
  if (data) {
    logger.warn(message, data);
  } else {
    logger.warn(message);
  }
};

const logError = (message: string, error?: unknown) => {
  logger.error(message, error);
};

let sqlInitPromise: Promise<SqlJsStatic> | null = null;
const sqlWasmUrl = new URL('sql.js/dist/sql-wasm.wasm', import.meta.url).toString();

/**
 * ğŸ”§ P0 ä¿®å¤ï¼šWASM åŠ è½½å¤±è´¥æ—¶é‡ç½®ç¼“å­˜ï¼Œå…è®¸åç»­é‡è¯•
 * 
 * æ—§å®ç°å¦‚æœ initSqlJs å¤±è´¥ï¼ˆç½‘ç»œé—®é¢˜ã€å†…å­˜ä¸è¶³ç­‰ï¼‰ï¼Œ
 * sqlInitPromise æ°¸è¿œæ˜¯ rejected çŠ¶æ€ï¼Œå¯¼è‡´æ‰€æœ‰ SQLite æ“ä½œæ°¸ä¹…å¤±æ•ˆã€‚
 * ç°åœ¨å¤±è´¥æ—¶æ¸…é™¤ç¼“å­˜ï¼Œä¸‹æ¬¡è°ƒç”¨ä¼šé‡è¯•ã€‚
 */
async function getSqlJs(): Promise<SqlJsStatic> {
  if (!sqlInitPromise) {
    sqlInitPromise = initSqlJs({
      locateFile: () => sqlWasmUrl,
    });
    // å¤±è´¥æ—¶é‡ç½®ï¼Œå…è®¸åç»­é‡è¯•
    sqlInitPromise.catch(() => {
      logWarn('sql.js WASM åŠ è½½å¤±è´¥ï¼Œå°†åœ¨ä¸‹æ¬¡æ“ä½œæ—¶é‡è¯•');
      sqlInitPromise = null;
    });
  }
  return sqlInitPromise;
}

function initSqliteSchema(db: Database) {
  db.exec(`
    PRAGMA journal_mode = WAL;
    PRAGMA synchronous = NORMAL;
    CREATE TABLE IF NOT EXISTS meta (
      key TEXT PRIMARY KEY,
      value TEXT
    );
    CREATE TABLE IF NOT EXISTS doc_updates (
      doc_id TEXT NOT NULL,
      ts INTEGER NOT NULL,
      bin BLOB NOT NULL
    );
    CREATE INDEX IF NOT EXISTS idx_doc_updates_doc ON doc_updates(doc_id);
    CREATE INDEX IF NOT EXISTS idx_doc_updates_doc_ts ON doc_updates(doc_id, ts);
    CREATE TABLE IF NOT EXISTS doc_snapshots (
      doc_id TEXT PRIMARY KEY,
      ts INTEGER NOT NULL,
      bin BLOB NOT NULL
    );
    CREATE TABLE IF NOT EXISTS doc_clocks (
      doc_id TEXT PRIMARY KEY,
      ts INTEGER NOT NULL
    );
    CREATE TABLE IF NOT EXISTS blobs (
      key TEXT PRIMARY KEY,
      data BLOB NOT NULL,
      mime TEXT,
      size INTEGER,
      created_at INTEGER
    );
    CREATE TABLE IF NOT EXISTS peer_clocks (
      peer TEXT NOT NULL,
      type TEXT NOT NULL,
      doc_id TEXT NOT NULL,
      ts INTEGER NOT NULL,
      PRIMARY KEY (peer, type, doc_id)
    );
    CREATE TABLE IF NOT EXISTS blob_uploaded_at (
      peer TEXT NOT NULL,
      blob_id TEXT NOT NULL,
      ts INTEGER NOT NULL,
      PRIMARY KEY (peer, blob_id)
    );
    CREATE TABLE IF NOT EXISTS v1_updates (
      id INTEGER PRIMARY KEY AUTOINCREMENT,
      doc_id TEXT,
      ts INTEGER NOT NULL,
      data BLOB NOT NULL
    );
    CREATE INDEX IF NOT EXISTS idx_v1_updates_doc ON v1_updates(doc_id);
    CREATE TABLE IF NOT EXISTS v1_blobs (
      key TEXT PRIMARY KEY,
      ts INTEGER NOT NULL,
      data BLOB NOT NULL
    );
    CREATE TABLE IF NOT EXISTS v1_server_clock (
      key TEXT PRIMARY KEY,
      ts INTEGER NOT NULL,
      data BLOB NOT NULL
    );
    CREATE TABLE IF NOT EXISTS v1_sync_metadata (
      key TEXT PRIMARY KEY,
      ts INTEGER NOT NULL,
      data BLOB NOT NULL
    );
    CREATE TABLE IF NOT EXISTS v1_meta (
      key TEXT PRIMARY KEY,
      value INTEGER
    );
  `);

  const stmt = db.prepare(
    'INSERT INTO meta (key, value) VALUES (?, ?) ON CONFLICT(key) DO UPDATE SET value=excluded.value'
  );
  stmt.bind(['schema_version', String(SQLITE_SCHEMA_VERSION)]);
  stmt.step();
  stmt.free();
}

function escapeFilename(name: string) {
  return name
    .replaceAll(/[\\/!@#$%^&*()+~`"':;,?<>|]/g, '_')
    .split('_')
    .filter(Boolean)
    .join('_');
}

async function getDbFileHandle(universalId: string): Promise<FileSystemFileHandle> {
  const root = await loadOfflineRootHandle();
  if (!root) {
    logWarn('offline root handle missing');
    throw new Error('ç¦»çº¿ç›®å½•æœªé€‰æ‹©');
  }
  const granted = await ensureHandlePermission(root);
  if (!granted) {
    logWarn('offline root permission denied', { root: root.name });
    throw new Error('ç¦»çº¿ç›®å½•æœªæˆæƒ');
  }
  const { peer, type, id } = parseUniversalId(universalId);
  const spaceDirName = type === 'userspace' ? 'userspaces' : 'workspaces';
  const spaceDir = await root.getDirectoryHandle(spaceDirName, { create: true });
  const peerDir = await spaceDir.getDirectoryHandle(escapeFilename(peer), {
    create: true,
  });
  const workspaceDir = await peerDir.getDirectoryHandle(id, { create: true });
  const handle = await workspaceDir.getFileHandle('storage.db', { create: true });
  logInfo('resolved db handle', {
    root: root.name,
    path: `${spaceDirName}/${escapeFilename(peer)}/${id}/storage.db`,
  });
  return handle;
}

async function getV1DbFileHandle(
  spaceType: SpaceType,
  workspaceId: string
): Promise<FileSystemFileHandle> {
  const root = await loadOfflineRootHandle();
  if (!root) {
    logWarn('offline root handle missing');
    throw new Error('ç¦»çº¿ç›®å½•æœªé€‰æ‹©');
  }
  const granted = await ensureHandlePermission(root);
  if (!granted) {
    logWarn('offline root permission denied', { root: root.name });
    throw new Error('ç¦»çº¿ç›®å½•æœªæˆæƒ');
  }
  const spaceDirName = spaceType === 'userspace' ? 'userspaces' : 'workspaces';
  const spaceDir = await root.getDirectoryHandle(spaceDirName, { create: true });
  const workspaceDir = await spaceDir.getDirectoryHandle(workspaceId, {
    create: true,
  });
  const handle = await workspaceDir.getFileHandle('storage.db', { create: true });
  logInfo('resolved v1 db handle', {
    root: root.name,
    path: `${spaceDirName}/${workspaceId}/storage.db`,
  });
  return handle;
}

function readFirstRow(db: Database, sql: string, params: unknown[]) {
  const stmt = db.prepare(sql);
  stmt.bind(params);
  if (!stmt.step()) {
    stmt.free();
    return null;
  }
  const row = stmt.getAsObject();
  stmt.free();
  return row;
}

function readAllRows(db: Database, sql: string, params: unknown[]) {
  const stmt = db.prepare(sql);
  stmt.bind(params);
  const rows: Record<string, any>[] = [];
  while (stmt.step()) {
    rows.push(stmt.getAsObject());
  }
  stmt.free();
  return rows;
}

function execStatement(db: Database, sql: string, params: unknown[]) {
  const stmt = db.prepare(sql);
  stmt.bind(params);
  stmt.step();
  stmt.free();
}

class SqliteFileEntry {
  db: Database;
  handle: FileSystemFileHandle;
  queue: Promise<unknown> = Promise.resolve();
  lastSize: number | null = null;
  
  // ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šé˜²æŠ– flush æœºåˆ¶ï¼Œé¿å…é¢‘ç¹å†™å…¥ç£ç›˜
  // ğŸ”§ P0 ä¿®å¤ï¼šæ”¹ä¸º publicï¼Œä¾› flushAllEntriesSync åŒæ­¥è®¿é—®
  flushTimer: ReturnType<typeof setTimeout> | null = null;
  flushDebounceMs = 500; // åˆå§‹ 500ms é˜²æŠ–å»¶è¿Ÿ
  pendingFlush = false;
  
  // ğŸ”§ P0 ä¼˜åŒ–ï¼šåŠ¨æ€é˜²æŠ–å»¶è¿Ÿå‚æ•°
  private static readonly MIN_DEBOUNCE_MS = 300;  // æœ€å°å»¶è¿Ÿ
  private static readonly MAX_DEBOUNCE_MS = 1500; // æœ€å¤§å»¶è¿Ÿ
  private static readonly DEBOUNCE_STEP = 100;    // è°ƒæ•´æ­¥é•¿
  private lastWriteTime = 0;
  private writeFrequencyWindow: number[] = [];    // æœ€è¿‘å†™å…¥æ—¶é—´çª—å£
  private static readonly FREQUENCY_WINDOW_SIZE = 10; // ç»Ÿè®¡çª—å£å¤§å°

  constructor(db: Database, handle: FileSystemFileHandle) {
    this.db = db;
    this.handle = handle;
  }

  /**
   * ğŸ”§ P0 ä¼˜åŒ–ï¼šæ ¹æ®å†™å…¥é¢‘ç‡åŠ¨æ€è°ƒæ•´é˜²æŠ–å»¶è¿Ÿ
   * 
   * - é«˜é¢‘å†™å…¥ï¼ˆ<100ms é—´éš”ï¼‰ï¼šå¢åŠ å»¶è¿Ÿï¼Œå‡å°‘ I/O
   * - ä½é¢‘å†™å…¥ï¼ˆ>2s é—´éš”ï¼‰ï¼šå‡å°‘å»¶è¿Ÿï¼Œæé«˜å“åº”æ€§
   */
  private updateDebounceDelay(): void {
    const now = Date.now();
    const timeSinceLastWrite = now - this.lastWriteTime;
    
    // è®°å½•å†™å…¥æ—¶é—´åˆ°çª—å£
    this.writeFrequencyWindow.push(now);
    if (this.writeFrequencyWindow.length > SqliteFileEntry.FREQUENCY_WINDOW_SIZE) {
      this.writeFrequencyWindow.shift();
    }
    
    // è®¡ç®—å¹³å‡å†™å…¥é—´éš”
    if (this.writeFrequencyWindow.length >= 3) {
      const intervals: number[] = [];
      for (let i = 1; i < this.writeFrequencyWindow.length; i++) {
        intervals.push(this.writeFrequencyWindow[i] - this.writeFrequencyWindow[i - 1]);
      }
      const avgInterval = intervals.reduce((a, b) => a + b, 0) / intervals.length;
      
      if (avgInterval < 100) {
        // é«˜é¢‘å†™å…¥ï¼šå¢åŠ å»¶è¿Ÿ
        this.flushDebounceMs = Math.min(
          SqliteFileEntry.MAX_DEBOUNCE_MS,
          this.flushDebounceMs + SqliteFileEntry.DEBOUNCE_STEP
        );
      } else if (avgInterval > 2000) {
        // ä½é¢‘å†™å…¥ï¼šå‡å°‘å»¶è¿Ÿ
        this.flushDebounceMs = Math.max(
          SqliteFileEntry.MIN_DEBOUNCE_MS,
          this.flushDebounceMs - SqliteFileEntry.DEBOUNCE_STEP
        );
      }
    } else if (timeSinceLastWrite < 100) {
      // çª—å£ä¸è¶³ä½†æ£€æµ‹åˆ°é«˜é¢‘å†™å…¥
      this.flushDebounceMs = Math.min(
        SqliteFileEntry.MAX_DEBOUNCE_MS,
        this.flushDebounceMs + SqliteFileEntry.DEBOUNCE_STEP
      );
    }
    
    this.lastWriteTime = now;
  }

  /**
   * ğŸ”§ P0 ä¼˜åŒ–ï¼šæ£€æŸ¥æ•°æ®åº“å®Œæ•´æ€§
   * ä½¿ç”¨ SQLite PRAGMA integrity_check éªŒè¯æ•°æ®å®Œæ•´æ€§
   */
  checkIntegrity(): { ok: boolean; errors: string[] } {
    try {
      const stmt = this.db.prepare('PRAGMA integrity_check');
      const errors: string[] = [];
      
      while (stmt.step()) {
        const row = stmt.getAsObject() as { integrity_check?: string };
        const result = row.integrity_check;
        if (result && result !== 'ok') {
          errors.push(result);
        }
      }
      stmt.free();
      
      const ok = errors.length === 0;
      if (!ok) {
        logWarn('æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥', {
          file: this.handle.name,
          errors,
        });
        emitStorageError({
          type: 'integrity-error',
          message: `æ•°æ®åº“å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: ${errors.join(', ')}`,
          details: { file: this.handle.name, errors },
        });
      }
      
      return { ok, errors };
    } catch (error) {
      const errorMsg = error instanceof Error ? error.message : String(error);
      logWarn('æ‰§è¡Œå®Œæ•´æ€§æ£€æŸ¥å¤±è´¥', {
        file: this.handle.name,
        error: errorMsg,
      });
      return { ok: false, errors: [errorMsg] };
    }
  }

  /**
   * ğŸ”§ P0 ä¼˜åŒ–ï¼šè·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
   */
  /**
   * ğŸ”§ P0 ä¿®å¤ï¼šç”¨ PRAGMA è·å–æ•°æ®åº“å¤§å°ï¼Œä¸å†è°ƒç”¨ db.export()
   * 
   * æ—§å®ç°ä¸ºäº†è·å– sizeBytes è°ƒç”¨ db.export()ï¼Œä¼šå°†æ•´ä¸ªæ•°æ®åº“å¤åˆ¶åˆ°å†…å­˜ã€‚
   * å¯¹äºå¤§æ•°æ®åº“ï¼ˆ100MB+ï¼‰ï¼Œè¿™ä¼šé€ æˆä¸¥é‡çš„å†…å­˜å³°å€¼å’Œ GC å‹åŠ›ã€‚
   * æ”¹ç”¨ page_count * page_size è®¡ç®—ï¼Œé›¶æ‹·è´ã€‚
   */
  getStats(): { docCount: number; blobCount: number; updateCount: number; sizeBytes: number } {
    try {
      const docCountRow = readFirstRow(this.db, 'SELECT COUNT(*) AS count FROM doc_snapshots', []) as { count?: number } | null;
      const blobCountRow = readFirstRow(this.db, 'SELECT COUNT(*) AS count FROM blobs', []) as { count?: number } | null;
      const updateCountRow = readFirstRow(this.db, 'SELECT COUNT(*) AS count FROM doc_updates', []) as { count?: number } | null;
      
      // ğŸ”§ P0 ä¿®å¤ï¼šä½¿ç”¨ PRAGMA è·å–æ•°æ®åº“å¤§å°ï¼Œé¿å… db.export() çš„å…¨é‡å†…å­˜å¤åˆ¶
      const pageSizeRow = readFirstRow(this.db, 'PRAGMA page_size', []) as { page_size?: number } | null;
      const pageCountRow = readFirstRow(this.db, 'PRAGMA page_count', []) as { page_count?: number } | null;
      const pageSize = pageSizeRow?.page_size ?? 4096;
      const pageCount = pageCountRow?.page_count ?? 0;
      
      return {
        docCount: docCountRow?.count ?? 0,
        blobCount: blobCountRow?.count ?? 0,
        updateCount: updateCountRow?.count ?? 0,
        sizeBytes: pageSize * pageCount,
      };
    } catch {
      return { docCount: 0, blobCount: 0, updateCount: 0, sizeBytes: 0 };
    }
  }

  /**
   * ğŸ”§ P0 ä¿®å¤ï¼šç¡®ä¿é˜Ÿåˆ—æ°¸è¿œä¸ä¼šæ–­è£‚
   * 
   * æ—§å®ç°ï¼šqueue = task.catch(log)
   * é—®é¢˜ï¼šå¦‚æœ action æŠ›å‡ºå¼‚å¸¸ï¼Œtask æ˜¯ rejected çš„ Promiseã€‚
   *   è™½ç„¶ catch åæ‰äº†é”™è¯¯è®© queue å˜æˆ resolvedï¼Œä½†ä¸‹ä¸€ä¸ª
   *   runExclusive çš„ action å¯èƒ½å› ä¸ºæ—¶åºé—®é¢˜æ‹¿åˆ°äº† rejected çš„ task
   *   è€Œä¸æ˜¯ catch åçš„ queueã€‚
   * 
   * æ–°å®ç°ï¼šqueue çš„ Promise é“¾å§‹ç»ˆ resolveï¼Œå³ä½¿ action å¤±è´¥ã€‚
   *   task å•ç‹¬è¿”å›ç»™è°ƒç”¨è€…ï¼Œè®©è°ƒç”¨è€…å¤„ç†é”™è¯¯ã€‚
   */
  async runExclusive<T>(action: () => Promise<T>): Promise<T> {
    let resolve!: (value: T) => void;
    let reject!: (reason: unknown) => void;
    const result = new Promise<T>((res, rej) => {
      resolve = res;
      reject = rej;
    });
    
    // é˜Ÿåˆ—çš„ Promise é“¾ï¼šæ— è®º action æˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œéƒ½ resolveï¼Œä¿æŒé“¾ä¸æ–­
    this.queue = this.queue.then(async () => {
      try {
        const value = await action();
        resolve(value);
      } catch (error) {
        logWarn('é˜Ÿåˆ—ä»»åŠ¡æ‰§è¡Œå¤±è´¥', {
          file: this.handle.name,
          error: error instanceof Error ? error.message : String(error),
        });
        reject(error);
      }
    });
    
    return result;
  }

  /**
   * ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šé˜²æŠ– flushï¼Œå»¶è¿Ÿå†™å…¥ç£ç›˜
   * å¤šæ¬¡å¿«é€Ÿå†™å…¥ä¼šè¢«åˆå¹¶ä¸ºä¸€æ¬¡ç£ç›˜å†™å…¥ï¼Œæ˜¾è‘—æå‡æ€§èƒ½
   * åŠ¨æ€è°ƒæ•´å»¶è¿Ÿæ—¶é—´ä»¥é€‚åº”ä¸åŒçš„å†™å…¥é¢‘ç‡
   */
  scheduleFlush(): void {
    this.pendingFlush = true;
    
    // ğŸ”§ P0 ä¼˜åŒ–ï¼šåŠ¨æ€è°ƒæ•´é˜²æŠ–å»¶è¿Ÿ
    this.updateDebounceDelay();
    
    if (this.flushTimer) {
      clearTimeout(this.flushTimer);
    }
    
    this.flushTimer = setTimeout(() => {
      this.flushTimer = null;
      if (this.pendingFlush) {
        this.pendingFlush = false;
        this.runExclusive(async () => {
          await this.flush();
        }).catch((error) => {
          logWarn('scheduled flush å¤±è´¥', {
            file: this.handle.name,
            error: error instanceof Error ? error.message : String(error),
          });
        });
      }
    }, this.flushDebounceMs);
  }

  /**
   * ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šç«‹å³ flushï¼Œç”¨äºå…³é”®æ“ä½œï¼ˆå¦‚ disconnectï¼‰
   * å–æ¶ˆå¾…å¤„ç†çš„é˜²æŠ– flushï¼Œç«‹å³æ‰§è¡Œ
   */
  async flushNow(): Promise<void> {
    if (this.flushTimer) {
      clearTimeout(this.flushTimer);
      this.flushTimer = null;
    }
    this.pendingFlush = false;
    await this.flush();
  }

  /**
   * ğŸ”§ Bug #16 ä¿®å¤ï¼šæ·»åŠ é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
   * ç¡®ä¿ç¦»çº¿æ•°æ®ä¸ä¼šå› å†™å…¥å¤±è´¥è€Œä¸¢å¤±
   */
  /**
   * ğŸ”§ P1 ä¿®å¤ï¼šå¢å¼º flush å®‰å…¨æ€§
   * 
   * File System Access API çš„ createWritable() é»˜è®¤ä½¿ç”¨åŸå­å†™å…¥ï¼š
   * æ•°æ®å…ˆå†™åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œclose() æ—¶æ‰æ›¿æ¢åŸæ–‡ä»¶ã€‚
   * å¦‚æœå†™å…¥è¿‡ç¨‹ä¸­é¡µé¢è¢«æ€ï¼Œabort() æˆ–æœª close() ä¼šä¿ç•™æ—§æ–‡ä»¶ä¸å˜ã€‚
   * 
   * è¿™é‡Œçš„å…³é”®æ”¹è¿›ï¼š
   * 1. æ·»åŠ  keepExistingData é€‰é¡¹ï¼šä¸æˆªæ–­ç°æœ‰æ–‡ä»¶ç›´åˆ° close
   * 2. å†™å…¥å‰æ£€æŸ¥ export æ•°æ®æœ‰æ•ˆæ€§ï¼ˆè‡³å°‘ > 100 bytesï¼‰
   * 3. å¤±è´¥æ—¶ç¡®ä¿æ­£ç¡® abortï¼Œä¸ä¼šå†™å…¥éƒ¨åˆ†æ•°æ®
   */
  async flush(maxRetries = 3): Promise<void> {
    const data = this.db.export();
    
    // ğŸ”§ P1 ä¿®å¤ï¼šå†™å…¥å‰æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§ï¼Œé˜²æ­¢å†™å…¥ç©ºæ•°æ®æˆ–æŸåæ•°æ®è¦†ç›–æ­£å¸¸æ–‡ä»¶
    if (!data || data.byteLength < 100) {
      logWarn('flush è·³è¿‡ï¼šå¯¼å‡ºæ•°æ®å¼‚å¸¸', {
        file: this.handle.name,
        bytes: data?.byteLength ?? 0,
      });
      return;
    }
    
    let lastError: Error | null = null;

    for (let attempt = 0; attempt < maxRetries; attempt++) {
      let writable: FileSystemWritableFileStream | null = null;
      try {
        // keepExistingData: falseï¼ˆé»˜è®¤ï¼‰= åŸå­æ›¿æ¢æ¨¡å¼
        // æ•°æ®å…ˆå†™ä¸´æ—¶æ–‡ä»¶ï¼Œclose() æ—¶åŸå­æ›¿æ¢ï¼Œä¸­é€”å¤±è´¥ä¸ä¼šæŸååŸæ–‡ä»¶
        writable = await this.handle.createWritable();
        await writable.write(data);
        await writable.close();
        writable = null; // close æˆåŠŸåç½®ç©ºï¼Œé˜²æ­¢ finally ä¸­é‡å¤æ“ä½œ
        
        if (data.length !== this.lastSize) {
          logInfo('flushed db file', {
            bytes: data.length,
            file: this.handle.name,
          });
          this.lastSize = data.length;
        }
        return; // æˆåŠŸï¼Œé€€å‡º
      } catch (error) {
        lastError = error instanceof Error ? error : new Error(String(error));
        logWarn('flush å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•', {
          file: this.handle.name,
          attempt: attempt + 1,
          maxRetries,
          error: lastError.message,
        });
        
        // ç¡®ä¿ abort writableï¼ˆæ”¾å¼ƒæœ¬æ¬¡å†™å…¥ï¼Œä¿ç•™æ—§æ–‡ä»¶å®Œæ•´ï¼‰
        if (writable) {
          try {
            await writable.abort();
          } catch {
            // å¿½ç•¥ abort é”™è¯¯
          }
        }
        
        // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç­‰å¾…åé‡è¯•
        if (attempt < maxRetries - 1) {
          await new Promise(resolve => setTimeout(resolve, 100 * Math.pow(2, attempt)));
        }
      }
    }

    // æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
    logWarn('flush æœ€ç»ˆå¤±è´¥ï¼Œæ•°æ®å¯èƒ½æœªä¿å­˜', {
      file: this.handle.name,
      error: lastError?.message ?? 'Unknown error',
    });
    logError('æ•°æ®å†™å…¥å¤±è´¥ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®ä¸¢å¤±', lastError);
    
    emitStorageError({
      type: 'write-failure',
      message: 'æ•°æ®ä¿å­˜å¤±è´¥ï¼Œå¯èƒ½å¯¼è‡´æ•°æ®ä¸¢å¤±ã€‚è¯·æ£€æŸ¥å­˜å‚¨ç©ºé—´å¹¶é‡è¯•ä¿å­˜ã€‚',
      details: {
        file: this.handle.name,
        error: lastError?.message,
      },
    });
  }
}

async function openSqliteEntry(handle: FileSystemFileHandle, checkIntegrity = true): Promise<SqliteFileEntry> {
  const sql = await getSqlJs();
  const file = await handle.getFile();
  const buffer = file.size > 0 ? new Uint8Array(await file.arrayBuffer()) : null;
  const db = buffer ? new sql.Database(buffer) : new sql.Database();
  initSqliteSchema(db);
  
  const entry = new SqliteFileEntry(db, handle);
  logInfo('opened db file', { file: handle.name, bytes: file.size });
  
  // ğŸ”§ P0 ä¼˜åŒ–ï¼šä»…å¯¹å·²æœ‰æ•°æ®çš„æ•°æ®åº“è¿›è¡Œå®Œæ•´æ€§æ£€æŸ¥
  if (checkIntegrity && buffer && buffer.length > 0) {
    const integrity = entry.checkIntegrity();
    if (!integrity.ok) {
      logWarn('æ•°æ®åº“å¯èƒ½å·²æŸåï¼Œä½†ä»å°è¯•ä½¿ç”¨', {
        file: handle.name,
        errors: integrity.errors,
      });
    }
  }
  
  return entry;
}

export function createFileNativeDBApis(): NativeDBApis {
  const entries = new Map<string, SqliteFileEntry>();

  // ğŸ”§ P0 ä¼˜åŒ–ï¼šåˆå§‹åŒ–æ—¶æ£€æŸ¥å­˜å‚¨ç©ºé—´
  checkAndWarnStorageQuota().catch((error) => {
    logWarn('åˆå§‹åŒ–å­˜å‚¨ç©ºé—´æ£€æŸ¥å¤±è´¥', {
      error: error instanceof Error ? error.message : String(error),
    });
  });

  // ğŸ”§ P0 ä¼˜åŒ–ï¼šå®šæœŸæ£€æŸ¥å­˜å‚¨ç©ºé—´ï¼ˆæ¯10åˆ†é’Ÿï¼‰
  const STORAGE_CHECK_INTERVAL = 10 * 60 * 1000;
  let storageCheckTimer: ReturnType<typeof setInterval> | null = null;
  
  if (typeof window !== 'undefined') {
    storageCheckTimer = setInterval(() => {
      checkAndWarnStorageQuota().catch(() => {
        // é™é»˜å¤±è´¥
      });
    }, STORAGE_CHECK_INTERVAL);

    // é¡µé¢å¸è½½æ—¶æ¸…ç†å®šæ—¶å™¨
    window.addEventListener('pagehide', () => {
      if (storageCheckTimer) {
        clearInterval(storageCheckTimer);
        storageCheckTimer = null;
      }
    });
  }

  // ğŸ”§ Bug #18 ä¿®å¤ï¼šæ·»åŠ é¡µé¢å¸è½½æ—¶çš„æ•°æ®ä¿å­˜æœºåˆ¶
  const flushAllEntries = async () => {
    const flushPromises: Promise<void>[] = [];
    for (const [id, entry] of entries) {
      flushPromises.push(
        entry.runExclusive(async () => {
          try {
            await entry.flush(1); // å¿«é€Ÿæ¨¡å¼ï¼Œåªé‡è¯•ä¸€æ¬¡
          } catch (error) {
            logWarn('é¡µé¢å¸è½½æ—¶ flush å¤±è´¥', {
              id,
              error: error instanceof Error ? error.message : String(error),
            });
          }
        })
      );
    }
    await Promise.allSettled(flushPromises);
  };

  /**
   * ğŸ”§ P0 ä¿®å¤ + P1 ä¿®å¤ï¼šåŒæ­¥ flush æ‰€æœ‰ entry
   * 
   * beforeunload / pagehide æ˜¯åŒæ­¥äº‹ä»¶ï¼Œæµè§ˆå™¨ä¸ä¼šç­‰å¾…å¼‚æ­¥æ“ä½œã€‚
   * è¿™é‡Œé‡‡ç”¨"å°½åŠ›è€Œä¸º"ç­–ç•¥ï¼šé€šè¿‡ runExclusive æ’é˜Ÿ flushï¼Œåˆ©ç”¨æµè§ˆå™¨ç»™äºˆçš„æœ‰é™æ—¶é—´çª—å£ã€‚
   * å®é™…çš„æ•°æ®å®‰å…¨ç”± visibilitychange äº‹ä»¶ä¿è¯ï¼ˆåœ¨é¡µé¢éšè—æ—¶æå‰ flushï¼‰ã€‚
   * 
   * ğŸ”§ P1 ä¿®å¤ï¼šé€šè¿‡ runExclusive æ’é˜Ÿï¼Œé¿å…ä¸æ­£åœ¨æ‰§è¡Œçš„å†™æ“ä½œå†²çªã€‚
   * æ—§å®ç°ç›´æ¥è°ƒç”¨ entry.flush()ï¼Œå¯èƒ½åŒæ—¶æœ‰ä¸¤ä¸ª createWritable() æ“ä½œåŒä¸€ä¸ªæ–‡ä»¶ã€‚
   */
  const flushAllEntriesSync = () => {
    for (const [id, entry] of entries) {
      if (entry.pendingFlush) {
        try {
          // å–æ¶ˆé˜²æŠ–å®šæ—¶å™¨
          if (entry.flushTimer) {
            clearTimeout(entry.flushTimer);
            entry.flushTimer = null;
          }
          entry.pendingFlush = false;
          // é€šè¿‡ runExclusive æ’é˜Ÿï¼Œé¿å…å’Œå…¶ä»–æ“ä½œå†²çª
          entry.runExclusive(async () => {
            await entry.flush(1);
          }).catch((error) => {
            logWarn('åŒæ­¥ flush å¤±è´¥', {
              id,
              error: error instanceof Error ? error.message : String(error),
            });
          });
        } catch (error) {
          logWarn('åŒæ­¥ flush å¼‚å¸¸', {
            id,
            error: error instanceof Error ? error.message : String(error),
          });
        }
      }
    }
  };

  // ğŸ”§ P1 ä¼˜åŒ–ï¼šäº‹ä»¶ç›‘å¬å™¨æ¸…ç†æœºåˆ¶ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
  let handleBeforeUnload: (() => void) | null = null;
  let handlePageHide: ((event: PageTransitionEvent) => void) | null = null;
  let handleVisibilityChange: (() => void) | null = null;
  let listenersRegistered = false;

  const registerUnloadListeners = () => {
    if (listenersRegistered || typeof window === 'undefined') {
      return;
    }

    /**
     * ğŸ”§ P0 ä¿®å¤ï¼švisibilitychange æ˜¯ç¦»çº¿æ•°æ®å®‰å…¨çš„æ ¸å¿ƒä¿éšœ
     * 
     * å½“ç”¨æˆ·åˆ‡æ¢ tabã€æœ€å°åŒ–çª—å£ã€åˆ‡æ¢åº”ç”¨æ—¶è§¦å‘ã€‚
     * æ­¤æ—¶æµè§ˆå™¨ä»ä¼šæ­£å¸¸æ‰§è¡Œå¼‚æ­¥æ“ä½œï¼Œæ˜¯ flush æ•°æ®çš„æœ€ä½³æ—¶æœºã€‚
     * åœ¨ç§»åŠ¨ç«¯å°¤å…¶é‡è¦ â€”â€” åˆ‡åˆ°åå°åé¡µé¢å¯èƒ½è¢«ç³»ç»Ÿç›´æ¥æ€æ­»ã€‚
     */
    handleVisibilityChange = () => {
      if (document.visibilityState === 'hidden') {
        logInfo('é¡µé¢ä¸å¯è§ï¼Œç«‹å³ flush æ‰€æœ‰æ•°æ®');
        flushAllEntries().catch((error) => {
          logError('visibilitychange flush å¤±è´¥', error);
        });
      }
    };

    handleBeforeUnload = () => {
      // ğŸ”§ P0 ä¿®å¤ï¼šbeforeunload ä¸­ä½¿ç”¨åŒæ­¥ç‰ˆæœ¬ï¼Œå°½åŠ›è€Œä¸º
      flushAllEntriesSync();
    };

    // ä½¿ç”¨ pagehide äº‹ä»¶ï¼ˆé¡µé¢çœŸæ­£è¢«å¸è½½æ—¶çš„æœ€åæœºä¼šï¼‰
    handlePageHide = (event: PageTransitionEvent) => {
      if (event.persisted) {
        // é¡µé¢è¢«ç¼“å­˜ï¼ˆbfcacheï¼‰ï¼Œä¸éœ€è¦ä¿å­˜
        return;
      }
      // ğŸ”§ P0 ä¿®å¤ï¼špagehide ä¸­ä¹Ÿä½¿ç”¨åŒæ­¥ç‰ˆæœ¬
      flushAllEntriesSync();
    };

    // ğŸ”§ P0 ä¿®å¤ï¼šä¼˜å…ˆçº§æœ€é«˜çš„æ˜¯ visibilitychangeï¼Œå®ƒèƒ½åœ¨é¡µé¢è¢«æ€æ­»å‰å¼‚æ­¥ flush
    document.addEventListener('visibilitychange', handleVisibilityChange);
    window.addEventListener('beforeunload', handleBeforeUnload);
    window.addEventListener('pagehide', handlePageHide);
    listenersRegistered = true;
    
    logInfo('å·²æ³¨å†Œé¡µé¢å¸è½½äº‹ä»¶ç›‘å¬å™¨ï¼ˆå« visibilitychangeï¼‰');
  };

  const unregisterUnloadListeners = () => {
    if (!listenersRegistered || typeof window === 'undefined') {
      return;
    }

    if (handleVisibilityChange) {
      document.removeEventListener('visibilitychange', handleVisibilityChange);
      handleVisibilityChange = null;
    }
    if (handleBeforeUnload) {
      window.removeEventListener('beforeunload', handleBeforeUnload);
      handleBeforeUnload = null;
    }
    if (handlePageHide) {
      window.removeEventListener('pagehide', handlePageHide);
      handlePageHide = null;
    }
    listenersRegistered = false;
    
    logInfo('å·²æ¸…ç†é¡µé¢å¸è½½äº‹ä»¶ç›‘å¬å™¨');
  };

  // åˆå§‹æ³¨å†Œç›‘å¬å™¨
  registerUnloadListeners();

  const getEntry = async (universalId: string) => {
    try {
      let entry = entries.get(universalId);
      if (!entry) {
        const handle = await getDbFileHandle(universalId);
        entry = await openSqliteEntry(handle);
        entries.set(universalId, entry);
        logInfo('created db entry', { id: universalId });
      }
      return entry;
    } catch (error) {
      logWarn('failed to open db entry', {
        id: universalId,
        error: error instanceof Error ? error.message : String(error),
      });
      throw error;
    }
  };

  const api: NativeDBApis = {
    connect: async (id: string) => {
      logInfo('connect', { id });
      await getEntry(id);
    },
    disconnect: async (id: string) => {
      const entry = entries.get(id);
      if (!entry) return;
      await entry.runExclusive(async () => {
        await entry.flushNow(); // å…³é”®æ“ä½œï¼Œç«‹å³ flush
        entry.db.close();
      });
      entries.delete(id);
      logInfo('disconnect', { id });
      
      // ğŸ”§ P1 ä¼˜åŒ–ï¼šæ‰€æœ‰è¿æ¥æ–­å¼€åæ¸…ç†ç›‘å¬å™¨å’Œå®šæ—¶å™¨ï¼ˆé˜²æ­¢å†…å­˜æ³„æ¼ï¼‰
      if (entries.size === 0) {
        unregisterUnloadListeners();
        if (storageCheckTimer) {
          clearInterval(storageCheckTimer);
          storageCheckTimer = null;
          logInfo('å·²æ¸…ç†å­˜å‚¨ç©ºé—´æ£€æŸ¥å®šæ—¶å™¨');
        }
      }
    },
    pushUpdate: async (id: string, docId: string, update: Uint8Array) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT MAX(ts) AS ts FROM doc_updates WHERE doc_id=?',
          [docId]
        ) as { ts?: number } | null;
        const now = Date.now();
        const ts = row?.ts ? Math.max(now, row.ts + 1) : now;
        
        // ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šä½¿ç”¨äº‹åŠ¡åŒ…è£¹å¤šæ¡ SQLï¼Œç¡®ä¿åŸå­æ€§å¹¶æå‡æ€§èƒ½
        entry.db.exec('BEGIN');
        try {
          execStatement(
            entry.db,
            'INSERT INTO doc_updates (doc_id, ts, bin) VALUES (?, ?, ?)',
            [docId, ts, update]
          );
          execStatement(
            entry.db,
            'INSERT INTO doc_clocks (doc_id, ts) VALUES (?, ?) ON CONFLICT(doc_id) DO UPDATE SET ts=excluded.ts',
            [docId, ts]
          );
          entry.db.exec('COMMIT');
        } catch (error) {
          entry.db.exec('ROLLBACK');
          throw error;
        }
        
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
        
        // ğŸ”§ P0 ä¿®å¤ï¼šè‡ªåŠ¨å‹ç¼© doc_updatesï¼Œé˜²æ­¢æ•°æ®åº“æ— é™è†¨èƒ€
        // åŒä¸€ä¸ª docId çš„ updates è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œåˆå¹¶ä¸º snapshot + æ¸…ç©º updates
        // è¿™æ˜¯ç¦»çº¿æ€§èƒ½çš„å…³é”®ï¼šDB è¶Šå° â†’ export è¶Šå¿« â†’ flush è¶Šå¿« â†’ å…³é—­é¡µé¢æ—¶æ•°æ®è¶Šå®‰å…¨
        const AUTO_COMPACT_THRESHOLD = 50; // æ¯ 50 æ¬¡ update å‹ç¼©ä¸€æ¬¡
        try {
          const countRow = readFirstRow(
            entry.db,
            'SELECT COUNT(*) AS cnt FROM doc_updates WHERE doc_id=?',
            [docId]
          ) as { cnt?: number } | null;
          const updateCount = countRow?.cnt ?? 0;
          
          if (updateCount >= AUTO_COMPACT_THRESHOLD) {
            // è¯»å–æ‰€æœ‰ updates
            const updateRows = readAllRows(
              entry.db,
              'SELECT bin FROM doc_updates WHERE doc_id=? ORDER BY ts ASC',
              [docId]
            ) as { bin?: Uint8Array }[];
            
            const updates: Uint8Array[] = [];
            // å…ˆè¯»å–ç°æœ‰ snapshot ä½œä¸ºåŸºç¡€
            const snapshotRow = readFirstRow(
              entry.db,
              'SELECT bin FROM doc_snapshots WHERE doc_id=?',
              [docId]
            ) as { bin?: Uint8Array } | null;
            if (snapshotRow?.bin && snapshotRow.bin.byteLength > 0) {
              updates.push(snapshotRow.bin);
            }
            for (const r of updateRows) {
              if (r.bin && r.bin.byteLength > 0) {
                updates.push(r.bin);
              }
            }
            
            if (updates.length > 1) {
              // åˆå¹¶ä¸ºæ–°çš„ snapshot
              const merged = mergeUpdates(updates);
              
              entry.db.exec('BEGIN');
              try {
                // ä¿å­˜åˆå¹¶åçš„ snapshot
                execStatement(
                  entry.db,
                  `INSERT INTO doc_snapshots (doc_id, ts, bin)
                   VALUES (?, ?, ?)
                   ON CONFLICT(doc_id) DO UPDATE SET ts=excluded.ts, bin=excluded.bin`,
                  [docId, ts, merged]
                );
                // æ¸…ç©ºæ‰€æœ‰ updatesï¼ˆå·²åˆå¹¶åˆ° snapshotï¼‰
                execStatement(
                  entry.db,
                  'DELETE FROM doc_updates WHERE doc_id=?',
                  [docId]
                );
                entry.db.exec('COMMIT');
                logInfo('auto-compacted doc_updates', {
                  docId,
                  updateCount,
                  snapshotSize: merged.byteLength,
                });
              } catch (compactError) {
                entry.db.exec('ROLLBACK');
                logWarn('auto-compact failed, skipping', {
                  docId,
                  error: compactError instanceof Error ? compactError.message : String(compactError),
                });
              }
            }
          }
        } catch {
          // å‹ç¼©å¤±è´¥ä¸å½±å“æ­£å¸¸ä¿å­˜
        }
        
        return new Date(ts);
      });
    },
    getDocSnapshot: async (id: string, docId: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT ts, bin FROM doc_snapshots WHERE doc_id=?',
          [docId]
        ) as { ts?: number; bin?: Uint8Array } | null;
        if (!row) return null;
        return {
          docId,
          bin: row.bin ?? new Uint8Array(),
          timestamp: new Date(row.ts ?? 0),
        } satisfies DocRecord;
      });
    },
    setDocSnapshot: async (id: string, snapshot: DocRecord) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        execStatement(
          entry.db,
          `INSERT INTO doc_snapshots (doc_id, ts, bin)
           VALUES (?, ?, ?)
           ON CONFLICT(doc_id) DO UPDATE SET ts=excluded.ts, bin=excluded.bin
           WHERE excluded.ts >= doc_snapshots.ts`,
          [snapshot.docId, snapshot.timestamp.getTime(), snapshot.bin]
        );
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
        return true;
      });
    },
    getDocUpdates: async (id: string, docId: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT ts, bin FROM doc_updates WHERE doc_id=? ORDER BY ts ASC',
          [docId]
        ) as { ts?: number; bin?: Uint8Array }[];
        return rows.map(row => ({
          docId,
          bin: row.bin ?? new Uint8Array(),
          timestamp: new Date(row.ts ?? 0),
        }));
      });
    },
    markUpdatesMerged: async (id: string, docId: string, updates: Date[]) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        // ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šäº‹åŠ¡ + é”™è¯¯å¤„ç†
        entry.db.exec('BEGIN');
        try {
          updates.forEach(update => {
            execStatement(
              entry.db,
              'DELETE FROM doc_updates WHERE doc_id=? AND ts=?',
              [docId, update.getTime()]
            );
          });
          entry.db.exec('COMMIT');
        } catch (error) {
          entry.db.exec('ROLLBACK');
          throw error;
        }
        entry.scheduleFlush();
        return updates.length;
      });
    },
    deleteDoc: async (id: string, docId: string) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        // ğŸ”§ æ€§èƒ½ä¼˜åŒ–ï¼šäº‹åŠ¡ + é”™è¯¯å¤„ç†
        entry.db.exec('BEGIN');
        try {
          execStatement(
            entry.db,
            'DELETE FROM doc_updates WHERE doc_id=?',
            [docId]
          );
          execStatement(
            entry.db,
            'DELETE FROM doc_snapshots WHERE doc_id=?',
            [docId]
          );
          execStatement(
            entry.db,
            'DELETE FROM doc_clocks WHERE doc_id=?',
            [docId]
          );
          entry.db.exec('COMMIT');
        } catch (error) {
          entry.db.exec('ROLLBACK');
          throw error;
        }
        entry.scheduleFlush();
      });
    },
    getDocClocks: async (id: string, after?: Date | null) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const rows = after
          ? readAllRows(
              entry.db,
              'SELECT doc_id AS docId, ts FROM doc_clocks WHERE ts > ?',
              [after.getTime()]
            )
          : readAllRows(
              entry.db,
              'SELECT doc_id AS docId, ts FROM doc_clocks',
              []
            );
        return rows.map(row => ({
          docId: row.docId as string,
          timestamp: new Date(row.ts as number),
        })) as DocClock[];
      });
    },
    getDocClock: async (id: string, docId: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT ts FROM doc_clocks WHERE doc_id=?',
          [docId]
        ) as { ts?: number } | null;
        if (!row) return null;
        return { docId, timestamp: new Date(row.ts ?? 0) } satisfies DocClock;
      });
    },
    getBlob: async (id: string, key: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT data, mime, size, created_at FROM blobs WHERE key=?',
          [key]
        ) as { data?: Uint8Array; mime?: string; size?: number; created_at?: number } | null;
        if (!row) return null;
        return {
          key,
          data: row.data ?? new Uint8Array(),
          mime: row.mime ?? '',
          size: row.size ?? 0,
          createdAt: new Date(row.created_at ?? Date.now()),
        } satisfies BlobRecord;
      });
    },
    setBlob: async (id: string, blob: BlobRecord) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        const meta = readFirstRow(
          entry.db,
          'SELECT created_at FROM blobs WHERE key=?',
          [blob.key]
        ) as { created_at?: number } | null;
        const createdAt = meta?.created_at ?? Date.now();
        execStatement(
          entry.db,
          `INSERT INTO blobs (key, data, mime, size, created_at)
           VALUES (?, ?, ?, ?, ?)
           ON CONFLICT(key) DO UPDATE SET data=excluded.data, mime=excluded.mime, size=excluded.size, created_at=blobs.created_at`,
          [
            blob.key,
            blob.data,
            blob.mime ?? null,
            blob.data.length,
            createdAt,
          ]
        );
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
      });
    },
    deleteBlob: async (id: string, key: string) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        execStatement(entry.db, 'DELETE FROM blobs WHERE key=?', [key]);
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
      });
    },
    releaseBlobs: async () => {
      return;
    },
    listBlobs: async (id: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT key, size, mime, created_at FROM blobs',
          []
        ) as { key?: string; size?: number; mime?: string; created_at?: number }[];
        return rows.map(row => ({
          key: row.key ?? '',
          size: row.size ?? 0,
          mime: row.mime ?? '',
          createdAt: new Date(row.created_at ?? Date.now()),
        })) satisfies ListedBlobRecord[];
      });
    },
    getPeerRemoteClocks: async (id: string, peer: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT doc_id AS docId, ts FROM peer_clocks WHERE peer=? AND type=?',
          [peer, 'remote']
        ) as { docId?: string; ts?: number }[];
        return rows.map(row => ({
          docId: row.docId ?? '',
          timestamp: new Date(row.ts ?? 0),
        })) as DocClock[];
      });
    },
    getPeerRemoteClock: async (id: string, peer: string, docId: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT ts FROM peer_clocks WHERE peer=? AND type=? AND doc_id=?',
          [peer, 'remote', docId]
        ) as { ts?: number } | null;
        if (!row) return null;
        return { docId, timestamp: new Date(row.ts ?? 0) } satisfies DocClock;
      });
    },
    setPeerRemoteClock: async (id: string, peer: string, docId: string, clock: Date) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        execStatement(
          entry.db,
          `INSERT INTO peer_clocks (peer, type, doc_id, ts)
           VALUES (?, ?, ?, ?)
           ON CONFLICT(peer, type, doc_id) DO UPDATE SET ts=excluded.ts`,
          [peer, 'remote', docId, clock.getTime()]
        );
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
      });
    },
    getPeerPulledRemoteClocks: async (id: string, peer: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT doc_id AS docId, ts FROM peer_clocks WHERE peer=? AND type=?',
          [peer, 'pulled']
        ) as { docId?: string; ts?: number }[];
        return rows.map(row => ({
          docId: row.docId ?? '',
          timestamp: new Date(row.ts ?? 0),
        })) as DocClock[];
      });
    },
    getPeerPulledRemoteClock: async (
      id: string,
      peer: string,
      docId: string
    ) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT ts FROM peer_clocks WHERE peer=? AND type=? AND doc_id=?',
          [peer, 'pulled', docId]
        ) as { ts?: number } | null;
        if (!row) return null;
        return { docId, timestamp: new Date(row.ts ?? 0) } satisfies DocClock;
      });
    },
    setPeerPulledRemoteClock: async (
      id: string,
      peer: string,
      docId: string,
      clock: Date
    ) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        execStatement(
          entry.db,
          `INSERT INTO peer_clocks (peer, type, doc_id, ts)
           VALUES (?, ?, ?, ?)
           ON CONFLICT(peer, type, doc_id) DO UPDATE SET ts=excluded.ts`,
          [peer, 'pulled', docId, clock.getTime()]
        );
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
      });
    },
    getPeerPushedClocks: async (id: string, peer: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT doc_id AS docId, ts FROM peer_clocks WHERE peer=? AND type=?',
          [peer, 'pushed']
        ) as { docId?: string; ts?: number }[];
        return rows.map(row => ({
          docId: row.docId ?? '',
          timestamp: new Date(row.ts ?? 0),
        })) as DocClock[];
      });
    },
    getPeerPushedClock: async (
      id: string,
      peer: string,
      docId: string
    ) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT ts FROM peer_clocks WHERE peer=? AND type=? AND doc_id=?',
          [peer, 'pushed', docId]
        ) as { ts?: number } | null;
        if (!row) return null;
        return { docId, timestamp: new Date(row.ts ?? 0) } satisfies DocClock;
      });
    },
    setPeerPushedClock: async (
      id: string,
      peer: string,
      docId: string,
      clock: Date
    ) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        execStatement(
          entry.db,
          `INSERT INTO peer_clocks (peer, type, doc_id, ts)
           VALUES (?, ?, ?, ?)
           ON CONFLICT(peer, type, doc_id) DO UPDATE SET ts=excluded.ts`,
          [peer, 'pushed', docId, clock.getTime()]
        );
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
      });
    },
    clearClocks: async (id: string) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        execStatement(entry.db, 'DELETE FROM peer_clocks', []);
        execStatement(entry.db, 'DELETE FROM blob_uploaded_at', []);
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
      });
    },
    setBlobUploadedAt: async (
      id: string,
      peer: string,
      blobId: string,
      uploadedAt: Date | null
    ) => {
      const entry = await getEntry(id);
      await entry.runExclusive(async () => {
        const ts = uploadedAt ? uploadedAt.getTime() : 0;
        execStatement(
          entry.db,
          `INSERT INTO blob_uploaded_at (peer, blob_id, ts)
           VALUES (?, ?, ?)
           ON CONFLICT(peer, blob_id) DO UPDATE SET ts=excluded.ts`,
          [peer, blobId, ts]
        );
        entry.scheduleFlush(); // ä½¿ç”¨é˜²æŠ– flushï¼Œæå‡æ€§èƒ½
      });
    },
    getBlobUploadedAt: async (id: string, peer: string, blobId: string) => {
      const entry = await getEntry(id);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT ts FROM blob_uploaded_at WHERE peer=? AND blob_id=?',
          [peer, blobId]
        ) as { ts?: number } | null;
        if (!row) return null;
        return new Date(row.ts ?? 0);
      });
    },
  };

  return api;
}

/**
 * ğŸ”§ P1 ä¿®å¤ï¼šV1 API æ·»åŠ è¿æ¥ç¼“å­˜
 * 
 * æ—§å®ç°æ¯æ¬¡è°ƒç”¨éƒ½æ–°å»º SQLite è¿æ¥åˆç«‹å³å…³é—­ï¼Œé¢‘ç¹è°ƒç”¨æ—¶æ€§èƒ½æå·®ã€‚
 * ç°åœ¨ä½¿ç”¨ Map ç¼“å­˜è¿æ¥ï¼Œé€šè¿‡ idle è¶…æ—¶è‡ªåŠ¨æ¸…ç†ã€‚
 */
export function createFileNativeDBV1Apis(): NativeDBV1Apis {
  const v1Entries = new Map<string, SqliteFileEntry>();
  const v1IdleTimers = new Map<string, ReturnType<typeof setTimeout>>();
  const V1_IDLE_TIMEOUT = 30000; // 30 ç§’æ— æ“ä½œåå…³é—­è¿æ¥
  
  const getV1CacheKey = (spaceType: SpaceType, workspaceId: string) => `${spaceType}:${workspaceId}`;
  
  const getV1Entry = async (spaceType: SpaceType, workspaceId: string): Promise<SqliteFileEntry> => {
    const key = getV1CacheKey(spaceType, workspaceId);
    let entry = v1Entries.get(key);
    
    if (!entry) {
      const handle = await getV1DbFileHandle(spaceType, workspaceId);
      entry = await openSqliteEntry(handle, false); // V1 åªè¯»ï¼Œä¸éœ€è¦å®Œæ•´æ€§æ£€æŸ¥
      v1Entries.set(key, entry);
    }
    
    // é‡ç½® idle å®šæ—¶å™¨
    const existingTimer = v1IdleTimers.get(key);
    if (existingTimer) {
      clearTimeout(existingTimer);
    }
    v1IdleTimers.set(key, setTimeout(() => {
      const cached = v1Entries.get(key);
      if (cached) {
        try {
          cached.db.close();
        } catch {
          // ignore
        }
        v1Entries.delete(key);
        v1IdleTimers.delete(key);
        logInfo('V1 è¿æ¥ idle è¶…æ—¶å·²å…³é—­', { key });
      }
    }, V1_IDLE_TIMEOUT));
    
    return entry;
  };
  
  return {
    getBlob: async (
      spaceType: SpaceType,
      workspaceId: string,
      key: string
    ) => {
      const entry = await getV1Entry(spaceType, workspaceId);
      return entry.runExclusive(async () => {
        const row = readFirstRow(
          entry.db,
          'SELECT data FROM v1_blobs WHERE key=?',
          [key]
        ) as { data?: Uint8Array } | null;
        if (!row?.data) return null;
        return row.data;
      });
    },
    getBlobKeys: async (spaceType: SpaceType, workspaceId: string) => {
      const entry = await getV1Entry(spaceType, workspaceId);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT key FROM v1_blobs',
          []
        ) as { key?: string }[];
        return rows.map(row => row.key ?? '');
      });
    },
    getDocAsUpdates: async (
      spaceType: SpaceType,
      workspaceId: string,
      subdocId: string
    ) => {
      const entry = await getV1Entry(spaceType, workspaceId);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT data FROM v1_updates WHERE doc_id IS ? ORDER BY id ASC',
          [subdocId]
        ) as { data?: Uint8Array }[];
        if (rows.length === 0) {
          return new Uint8Array([0, 0]);
        }
        const updates = rows.map(row => row.data ?? new Uint8Array());
        return mergeUpdates(updates);
      });
    },
    getDocTimestamps: async (spaceType: SpaceType, workspaceId: string) => {
      const entry = await getV1Entry(spaceType, workspaceId);
      return entry.runExclusive(async () => {
        const rows = readAllRows(
          entry.db,
          'SELECT doc_id AS docId, MAX(ts) AS ts FROM v1_updates WHERE doc_id IS NOT NULL GROUP BY doc_id',
          []
        ) as { docId?: string; ts?: number }[];
        return rows.map(row => ({
          docId: row.docId,
          timestamp: new Date(row.ts ?? 0),
        }));
      });
    },
  };
}
